{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "tpnaqgx3dwrvl7nnydns",
   "authorId": "3919642301233",
   "authorName": "JAMESE",
   "authorEmail": "james.cha-earley@snowflake.com",
   "sessionId": "b73eac14-2b50-454d-849a-f2ff5c48a2b6",
   "lastEditTime": 1761068017623
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4bea9b7-950d-41b2-9c93-eca76f43d930",
   "metadata": {
    "name": "INTRO",
    "collapsed": false
   },
   "source": "# From Dev to Production\n## Call Center Quality Analysis with Acoustic Features\n## This notebook demonstrates the complete ML lifecycle in Snowflake:\n1. ü§ó Deploy HuggingFace model for feature generation\n2. üî® Build end-to-end ML model\n3. üìä Track experiments and metrics\n4. üöÄ Deploy model for inference\n5. ‚ö° Enable online feature store"
  },
  {
   "cell_type": "code",
   "id": "25d43312-4e7f-4704-9db5-eb8367b1825d",
   "metadata": {
    "language": "python",
    "name": "PIP_INSTALLS"
   },
   "outputs": [],
   "source": "!pip install torch transformers librosa soundfile torchaudio praat-parselmouth pyannote.audio speechbrain openai-whisper resampy imbalanced-learn",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "LIBRARY_SETUP",
    "codeCollapsed": false
   },
   "source": "# Import required libraries\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.functions import col, lit\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.experiment.experiment_tracking import ExperimentTracking\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nimport pandas as pd\nimport numpy as np\nimport whisper\nfrom transformers import pipeline\nimport librosa\nimport warnings\nimport resampy\nfrom datetime import datetime\nimport soundfile as sf\nfrom scipy import signal\n\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f5b2bed0-1304-4d20-a46b-daed1b2f2ff1",
   "metadata": {
    "language": "python",
    "name": "PREP_AUDIO_FILES",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Create a list of audio files from the stage\nsession.sql(\"\"\"\n    CREATE OR REPLACE TABLE BUILD25_DEV_TO_PRODUCTION.DATA.audio_file_list AS \n    SELECT \n        RELATIVE_PATH AS file_name,\n        '@BUILD25_DEV_TO_PRODUCTION.DATA.audio_files/' || RELATIVE_PATH AS file_path,\n        SIZE AS file_size_bytes,\n        LAST_MODIFIED\n    FROM DIRECTORY(@BUILD25_DEV_TO_PRODUCTION.DATA.audio_files)\n    WHERE RELATIVE_PATH LIKE '%.wav' \n       OR RELATIVE_PATH LIKE '%.mp3'\n       OR RELATIVE_PATH LIKE '%.flac'\n\"\"\").collect()\n\nfile_count = session.sql(\"\"\"\n    SELECT COUNT(*) as file_count \n    FROM BUILD25_DEV_TO_PRODUCTION.DATA.audio_file_list\n\"\"\").collect()[0]['FILE_COUNT']\n\nprint(f\"‚úì Found {file_count} audio files in stage\")\n\n# Show sample files\nprint(\"\\nSample audio files:\")\nsession.table(\"BUILD25_DEV_TO_PRODUCTION.DATA.audio_file_list\").limit(5).show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "name": "DEPLOY_HUGGING_FACE",
    "collapsed": false
   },
   "source": "## Step 1: Deploy HuggingFace Model\n \n**‚ú® NEW: HuggingFace Model Deployment UI**\n \n We'll deploy an acoustic feature extractor that analyzes call audio to extract:\n - Speech patterns (rate, pauses, rhythm)\n - Voice characteristics (pitch, tone, energy)\n - Interaction dynamics (interruptions, turn-taking)\n - Emotional indicators (stress, emotion trajectory)\n \n### In the HuggingFace Deployment UI:\n1. Browse Model Hub ‚Üí Select `tabularisai/multilingual-sentiment-analysis`\n2. Configure input/output\n3. Click 'Deploy'"
  },
  {
   "cell_type": "code",
   "id": "66058475-6729-44b0-bb99-365076c825b0",
   "metadata": {
    "language": "python",
    "name": "DATA_SET_PREP"
   },
   "outputs": [],
   "source": "\"\"\"\nSnowflake Audio Feature Extraction Script\nProcesses all audio files from a Snowflake stage and saves features to a table.\nUses Whisper for transcription and Snowflake Model Registry for sentiment analysis.\n\"\"\"\n\nimport snowflake.snowpark as snowpark\nfrom snowflake.ml.registry import Registry\nfrom snowflake.snowpark.functions import col\nimport pandas as pd\nimport numpy as np\nimport whisper\nfrom transformers import pipeline\nimport librosa\nimport warnings\nimport os\nimport tempfile\nimport soundfile as sf\nfrom scipy import signal\n \nwarnings.filterwarnings('ignore')\n# Suppress specific librosa warnings\nimport logging\nlogging.getLogger('librosa').setLevel(logging.ERROR)\n\n\n# ============================================================================\n# ACOUSTIC FEATURE EXTRACTOR (Using Whisper + Snowflake Model Registry)\n# ============================================================================\n\nclass HuggingFaceAcousticExtractor:\n    \"\"\"Extract acoustic features using Whisper + HuggingFace models + Librosa + Snowflake Registry.\"\"\"\n    \n    def __init__(self, whisper_model_size=\"base\", session=None):\n        print(\"Loading models...\")\n        \n        # Store session for model registry access\n        self.session = session\n        \n        # Whisper for transcription\n        print(f\"  Loading Whisper ({whisper_model_size})...\")\n        self.whisper_model = whisper.load_model(whisper_model_size)\n        \n        # Emotion recognition\n        print(\"  Loading emotion model...\")\n        self.emotion_pipeline = pipeline(\n            \"audio-classification\",\n            model=\"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\"\n        )\n        \n        # Named Entity Recognition\n        print(\"  Loading NER model (BERT)...\")\n        self.ner_pipeline = pipeline(\n            \"ner\",\n            model=\"dslim/bert-base-NER\",\n            aggregation_strategy=\"simple\"\n        )\n        \n        # Multilingual Sentiment Analysis - Using Snowflake Model Registry\n        print(\"  Loading sentiment model from Snowflake Model Registry...\")\n        if self.session:\n            try:\n                \n                \n                # Get the registry\n                reg = Registry(session=self.session)\n                \n                # Get the model - adjust database/schema as needed\n                self.sentiment_model = reg.get_model(\n                    \"MULTILINGUAL_SENTIMENT_ANALYSIS\"\n                ).default\n                \n                print(\"  ‚úì Sentiment model loaded from Snowflake Model Registry\")\n                self.use_registry_sentiment = True\n            except Exception as e:\n                print(f\"  Warning: Could not load from registry ({e}), falling back to HuggingFace\")\n                self.sentiment_pipeline = pipeline(\n                    \"sentiment-analysis\",\n                    model=\"tabularisai/multilingual-sentiment-analysis\"\n                )\n                self.use_registry_sentiment = False\n        else:\n            print(\"  Warning: No session provided, using HuggingFace model\")\n            self.sentiment_pipeline = pipeline(\n                \"sentiment-analysis\",\n                model=\"tabularisai/multilingual-sentiment-analysis\"\n            )\n            self.use_registry_sentiment = False\n        \n        print(\"‚úì Models loaded successfully\")\n    \n    def analyze_sentiment_with_registry(self, text: str):\n        \"\"\"Analyze sentiment using Snowflake Model Registry.\"\"\"\n        try:\n            # Truncate text to reasonable length\n            text_truncated = text[:512]\n            \n            # Create a pandas DataFrame with the text\n            import pandas as pd\n            input_df = pd.DataFrame({'text': [text_truncated]})\n            \n            # Convert to Snowpark DataFrame\n            input_sp = self.session.create_dataframe(input_df)\n            \n            # Run prediction using the model\n            result_sp = self.sentiment_model.run(input_sp, function_name=\"predict\")\n            \n            # Convert back to pandas to extract results\n            result_pd = result_sp.to_pandas()\n            \n            # Extract label and score - adjust column names based on your model's output\n            # Common output formats: 'label', 'LABEL', 'prediction', etc.\n            if 'label' in result_pd.columns:\n                sentiment_label = result_pd['label'].iloc[0].lower()\n            elif 'LABEL' in result_pd.columns:\n                sentiment_label = result_pd['LABEL'].iloc[0].lower()\n            else:\n                # Print available columns to debug\n                print(f\"      Available columns: {result_pd.columns.tolist()}\")\n                sentiment_label = 'neutral'\n            \n            if 'score' in result_pd.columns:\n                sentiment_score = float(result_pd['score'].iloc[0])\n            elif 'SCORE' in result_pd.columns:\n                sentiment_score = float(result_pd['SCORE'].iloc[0])\n            else:\n                sentiment_score = 0.5\n            \n            return sentiment_label, sentiment_score\n                \n        except Exception as e:\n            print(f\"      Registry sentiment analysis failed: {e}\")\n            import traceback\n            traceback.print_exc()\n            return 'neutral', 0.5\n    \n    def extract_all_features(self, audio_path: str) -> dict:\n        \"\"\"Extract all acoustic features from audio file.\"\"\"\n        try:\n            # Verify file exists and is readable\n            if not os.path.exists(audio_path):\n                print(f\"      Error: File does not exist: {audio_path}\")\n                return None\n            \n            file_size = os.path.getsize(audio_path)\n            if file_size == 0:\n                print(f\"      Error: File is empty (0 bytes)\")\n                return None\n            \n            print(f\"      Loading audio file ({file_size} bytes)...\")\n            \n            # Load audio - use soundfile + scipy for resampling (no resampy dependency)\n            try:\n                # Load with soundfile\n                audio, sr = sf.read(audio_path)\n                \n                # Convert stereo to mono if needed\n                if len(audio.shape) > 1:\n                    audio = np.mean(audio, axis=1)\n                \n                # Resample to 16kHz using scipy if needed\n                if sr != 16000:\n                    print(f\"      Resampling from {sr}Hz to 16000Hz...\")\n                    # Calculate number of samples in output\n                    num_samples = int(len(audio) * 16000 / sr)\n                    # Use scipy's resample function\n                    audio = signal.resample(audio, num_samples)\n                    sr = 16000\n                    \n            except Exception as audio_error:\n                print(f\"      Error: Could not load audio file: {audio_error}\")\n                return None\n            \n            duration_sec = len(audio) / sr\n            duration_minutes = duration_sec / 60\n            \n            print(f\"      Audio loaded: {duration_sec:.2f}s, {sr}Hz\")\n            \n            # Get transcription for word count using Whisper\n            word_count = 0\n            transcript_text = \"\"\n            try:\n                print(f\"      Transcribing with Whisper...\")\n                result = self.whisper_model.transcribe(audio_path, fp16=False)\n                transcript_text = result['text']\n                word_count = len(transcript_text.split())\n                print(f\"      Transcribed: {word_count} words\")\n            except Exception as e:\n                print(f\"      Transcription failed: {e}\")\n            \n            # Calculate RMS energy for speech detection\n            frame_length = 2048\n            hop_length = 512\n            rms = librosa.feature.rms(y=audio, frame_length=frame_length, hop_length=hop_length)[0]\n            threshold = np.mean(rms) * 0.3\n            speech_frames = rms > threshold\n            \n            # Speech rate features\n            speaking_rate_wpm = float(word_count / duration_minutes if duration_minutes > 0 else 0)\n            speech_energy = rms[speech_frames]\n            speech_rate_variability = float(\n                np.std(speech_energy) / np.mean(speech_energy) \n                if len(speech_energy) > 0 else 0\n            )\n            \n            # Pause features\n            frame_duration = hop_length / sr\n            transitions = np.diff(speech_frames.astype(int))\n            pause_count = int(np.sum(transitions == -1))\n            pause_frequency = float(pause_count / duration_minutes if duration_minutes > 0 else 0)\n            \n            # Calculate pause durations\n            non_speech_segments = []\n            in_pause = False\n            pause_start = 0\n            for i, is_speech in enumerate(speech_frames):\n                if not is_speech and not in_pause:\n                    in_pause = True\n                    pause_start = i\n                elif is_speech and in_pause:\n                    in_pause = False\n                    non_speech_segments.append(i - pause_start)\n            \n            avg_pause_duration = float(\n                np.mean(non_speech_segments) * frame_duration \n                if non_speech_segments else 0\n            )\n            \n            # Pitch features\n            pitches, magnitudes = librosa.piptrack(y=audio, sr=sr, fmin=75, fmax=300)\n            pitch_values = []\n            for t in range(pitches.shape[1]):\n                index = magnitudes[:, t].argmax()\n                pitch = pitches[index, t]\n                if pitch > 0:\n                    pitch_values.append(pitch)\n            \n            if len(pitch_values) > 10:\n                avg_pitch_hz = float(np.mean(pitch_values))\n                pitch_variance = float(np.var(pitch_values))\n                pitch_range_hz = float(np.max(pitch_values) - np.min(pitch_values))\n            else:\n                avg_pitch_hz = 0.0\n                pitch_variance = 0.0\n                pitch_range_hz = 0.0\n            \n            # Energy features\n            energy_mean = float(np.mean(rms))\n            energy_variance = float(np.var(rms))\n            rms_db = librosa.amplitude_to_db(rms)\n            dynamic_range_db = float(np.max(rms_db) - np.min(rms_db))\n            \n            # Spectral features\n            spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]\n            spectral_centroid_mean = float(np.mean(spectral_centroid))\n            zcr = librosa.feature.zero_crossing_rate(audio)[0]\n            zcr_mean = float(np.mean(zcr))\n            \n            # Voice quality\n            jitter = float(np.std(np.diff(zcr)) * 0.01)\n            shimmer = float(energy_variance * 0.1)\n            harmonics_to_noise_ratio = float(\n                min(energy_mean / (energy_variance + 1e-10) * 10, 20.0)\n            )\n            \n            # Silence features\n            silence_ratio = float(1.0 - np.mean(speech_frames))\n            speech_ratio = float(np.mean(speech_frames))\n            speech_to_silence_ratio = float(\n                speech_ratio / silence_ratio if silence_ratio > 0.01 else 10.0\n            )\n            \n            # Interaction features\n            energy_diff = np.abs(np.diff(rms))\n            threshold_interruption = np.mean(energy_diff) + 1.5 * np.std(energy_diff)\n            interruptions = int(np.sum(energy_diff > threshold_interruption))\n            interruption_count = int(min(interruptions / 20, 15))\n            \n            high_energy = rms > np.percentile(rms, 60)\n            transitions_energy = int(np.sum(np.abs(np.diff(high_energy.astype(int)))))\n            turn_taking_rate = float(\n                transitions_energy / 2 / duration_minutes if duration_minutes > 0 else 0\n            )\n            agent_talk_ratio = float(np.mean(high_energy))\n            \n            # Turn duration\n            turn_durations = []\n            current_turn = 0\n            for i in range(1, len(high_energy)):\n                if high_energy[i] == high_energy[i-1]:\n                    current_turn += 1\n                else:\n                    if current_turn > 0:\n                        turn_durations.append(current_turn)\n                    current_turn = 0\n            \n            avg_turn_duration = float(\n                np.mean(turn_durations) * frame_duration if turn_durations else 0\n            )\n            \n            # Get emotions using HuggingFace model\n            try:\n                print(f\"      Analyzing emotions...\")\n                emotions = self.emotion_pipeline(audio_path)\n                negative_emotions = ['angry', 'disgust', 'fearful', 'sad']\n                negative_score = sum(\n                    e['score'] for e in emotions \n                    if e['label'] in negative_emotions\n                )\n                stress_score = sum(\n                    e['score'] for e in emotions \n                    if e['label'] in ['angry', 'fearful']\n                )\n                dominant_emotion = max(emotions, key=lambda x: x['score'])['label']\n                print(f\"      Emotion: {dominant_emotion} (stress: {stress_score:.3f})\")\n            except Exception as e:\n                print(f\"      Emotion detection failed: {e}\")\n                negative_score = 0.0\n                stress_score = 0.0\n                dominant_emotion = 'unknown'\n            \n            # Emotion volatility from energy patterns\n            num_windows = 6\n            window_size = len(rms) // num_windows\n            emotion_scores = []\n            for i in range(num_windows):\n                start = i * window_size\n                end = min(start + window_size, len(rms))\n                if end - start >= 10:\n                    window_rms = rms[start:end]\n                    window_spectral = spectral_centroid[start:end]\n                    energy_var = np.var(window_rms)\n                    spectral_var = np.var(window_spectral)\n                    score = (energy_var / (np.mean(window_rms) + 1e-10) + \n                            spectral_var / (np.mean(window_spectral) + 1e-10)) / 2\n                    emotion_scores.append(min(score * 0.1, 1.0))\n            \n            emotion_volatility = float(\n                np.std(emotion_scores) if len(emotion_scores) > 1 else 0\n            )\n            \n            # Extract named entities from transcript using BERT NER\n            entities_person = []\n            entities_org = []\n            entities_loc = []\n            entities_misc = []\n            entity_count = 0\n            \n            # Sentiment analysis from transcript\n            sentiment_label = 'neutral'\n            sentiment_score = 0.5\n            \n            if transcript_text and len(transcript_text.strip()) > 0:\n                try:\n                    print(f\"      Extracting named entities...\")\n                    ner_results = self.ner_pipeline(transcript_text)\n                    \n                    for entity in ner_results:\n                        entity_type = entity['entity_group']\n                        entity_text = entity['word']\n                        \n                        if entity_type == 'PER':\n                            entities_person.append(entity_text)\n                        elif entity_type == 'ORG':\n                            entities_org.append(entity_text)\n                        elif entity_type == 'LOC':\n                            entities_loc.append(entity_text)\n                        elif entity_type == 'MISC':\n                            entities_misc.append(entity_text)\n                    \n                    entity_count = len(ner_results)\n                    print(f\"      Found {entity_count} entities: {len(entities_person)} persons, {len(entities_org)} orgs, {len(entities_loc)} locations\")\n                    \n                except Exception as e:\n                    print(f\"      NER failed: {e}\")\n                \n                # Analyze sentiment from transcript - use Registry or HuggingFace\n                try:\n                    print(f\"      Analyzing transcript sentiment...\")\n                    if self.use_registry_sentiment:\n                        sentiment_label, sentiment_score = self.analyze_sentiment_with_registry(transcript_text)\n                        print(f\"      Sentiment (Registry): {sentiment_label} (confidence: {sentiment_score:.3f})\")\n                    else:\n                        sentiment_result = self.sentiment_pipeline(transcript_text[:512])\n                        sentiment_label = sentiment_result[0]['label'].lower()\n                        sentiment_score = sentiment_result[0]['score']\n                        print(f\"      Sentiment (HuggingFace): {sentiment_label} (confidence: {sentiment_score:.3f})\")\n                except Exception as e:\n                    print(f\"      Sentiment analysis failed: {e}\")\n            \n            print(f\"      ‚úì All features extracted successfully\")\n            \n            return {\n                'speaking_rate_wpm': speaking_rate_wpm,\n                'speech_rate_variability': speech_rate_variability,\n                'avg_pause_duration_sec': avg_pause_duration,\n                'pause_frequency_per_min': pause_frequency,\n                'avg_pitch_hz': avg_pitch_hz,\n                'pitch_variance': pitch_variance,\n                'pitch_range_hz': pitch_range_hz,\n                'energy_mean': energy_mean,\n                'energy_variance': energy_variance,\n                'dynamic_range_db': dynamic_range_db,\n                'spectral_centroid': spectral_centroid_mean,\n                'harmonics_to_noise_ratio': harmonics_to_noise_ratio,\n                'jitter': jitter,\n                'shimmer': shimmer,\n                'zero_crossing_rate': zcr_mean,\n                'silence_ratio': silence_ratio,\n                'speech_to_silence_ratio': speech_to_silence_ratio,\n                'interruption_count': interruption_count,\n                'agent_talk_ratio': agent_talk_ratio,\n                'turn_taking_rate': turn_taking_rate,\n                'avg_turn_duration_sec': avg_turn_duration,\n                'avg_emotion_score': float(negative_score),\n                'emotion_volatility': emotion_volatility,\n                'stress_indicators': float(stress_score),\n                'dominant_emotion': dominant_emotion,\n                'transcript': transcript_text,\n                'word_count': word_count,\n                'entity_count': entity_count,\n                'entities_person': ','.join(entities_person) if entities_person else '',\n                'entities_org': ','.join(entities_org) if entities_org else '',\n                'entities_loc': ','.join(entities_loc) if entities_loc else '',\n                'entities_misc': ','.join(entities_misc) if entities_misc else '',\n                'sentiment_label': sentiment_label,\n                'sentiment_score': float(sentiment_score)\n            }\n        except Exception as e:\n            print(f\"      ‚úó Error processing audio: {e}\")\n            import traceback\n            traceback.print_exc()\n            return None\n\n\n# ============================================================================\n# SNOWFLAKE PROCESSING SCRIPT\n# ============================================================================\n\ndef process_stage_audio_files(session: snowpark.Session):\n    \"\"\"\n    Process all audio files from Snowflake stage and save features to table.\n    \"\"\"\n    \n    print(\"=\"*80)\n    print(\"SNOWFLAKE AUDIO FEATURE EXTRACTION\")\n    print(\"=\"*80)\n    \n    # Step 1: Enable directory on stage\n    print(\"\\n1. Enabling directory on stage...\")\n    try:\n        session.sql(\"\"\"\n            ALTER STAGE BUILD25_DEV_TO_PRODUCTION.DATA.audio_files \n            SET DIRECTORY = (ENABLE = TRUE)\n        \"\"\").collect()\n        print(\"   ‚úì Directory enabled\")\n    except Exception as e:\n        print(f\"   Note: Directory may already be enabled ({e})\")\n    \n    # Step 2: Create list of audio files\n    print(\"\\n2. Getting list of audio files from stage...\")\n    session.sql(\"\"\"\n        CREATE OR REPLACE TABLE BUILD25_DEV_TO_PRODUCTION.DATA.audio_file_list AS \n        SELECT \n            RELATIVE_PATH AS file_name,\n            '@BUILD25_DEV_TO_PRODUCTION.DATA.audio_files/' || RELATIVE_PATH AS file_path,\n            SIZE AS file_size_bytes,\n            LAST_MODIFIED\n        FROM DIRECTORY(@BUILD25_DEV_TO_PRODUCTION.DATA.audio_files)\n        WHERE RELATIVE_PATH LIKE '%.wav' \n           OR RELATIVE_PATH LIKE '%.mp3'\n           OR RELATIVE_PATH LIKE '%.flac'\n    \"\"\").collect()\n    \n    file_count = session.sql(\"\"\"\n        SELECT COUNT(*) as file_count \n        FROM BUILD25_DEV_TO_PRODUCTION.DATA.audio_file_list\n    \"\"\").collect()[0]['FILE_COUNT']\n    \n    print(f\"   ‚úì Found {file_count} audio files\")\n    \n    # Show sample\n    print(\"\\n   Sample files:\")\n    session.table(\"BUILD25_DEV_TO_PRODUCTION.DATA.audio_file_list\").limit(5).show()\n    \n    # Step 3: Get files as pandas DataFrame\n    print(\"\\n3. Loading file list...\")\n    audio_files_df = session.table(\"BUILD25_DEV_TO_PRODUCTION.DATA.audio_file_list\").to_pandas()\n    print(f\"   ‚úì Loaded {len(audio_files_df)} files\")\n    \n    # Step 4: Initialize feature extractor (pass session for model registry)\n    print(\"\\n4. Initializing Whisper and models...\")\n    extractor = HuggingFaceAcousticExtractor(whisper_model_size=\"base\", session=session)\n    \n    # Step 5: Create temporary directory for downloaded files\n    print(\"\\n5. Setting up temporary directory for audio files...\")\n    temp_dir = tempfile.mkdtemp(prefix=\"snowflake_audio_\")\n    print(f\"   ‚úì Temporary directory: {temp_dir}\")\n    \n    # Step 6: Process all audio files\n    print(f\"\\n6. Processing {len(audio_files_df)} audio files...\")\n    print(\"   This may take a while depending on file count...\\n\")\n    \n    features_list = []\n    errors = []\n    \n    for idx, row in audio_files_df.iterrows():\n        stage_path = row['FILE_PATH']\n        file_name = row['FILE_NAME']\n        \n        # Extract call metadata from filename\n        parts = file_name.replace('.wav', '').replace('.mp3', '').replace('.flac', '').split('_')\n        call_id = parts[0] if len(parts) > 0 else f'call_{idx}'\n        agent_id = parts[1] if len(parts) > 1 else f'agent_{idx % 10}'\n        \n        print(f\"   Processing [{idx+1}/{len(audio_files_df)}]: {file_name}\")\n        \n        try:\n            # Download file from stage to local temp directory\n            local_path = os.path.join(temp_dir, file_name)\n            print(f\"      Downloading from stage: {stage_path}\")\n            \n            # Use GET command to download file\n            get_result = session.file.get(stage_path, temp_dir)\n            print(f\"      Download result: {get_result}\")\n            \n            # Verify file exists and check size\n            if not os.path.exists(local_path):\n                # Try alternate path (sometimes GET creates subdirectories)\n                alt_path = os.path.join(temp_dir, os.path.basename(file_name))\n                if os.path.exists(alt_path):\n                    local_path = alt_path\n                else:\n                    print(f\"      ‚úó Error: File not found after download\")\n                    print(f\"         Expected: {local_path}\")\n                    print(f\"         Directory contents: {os.listdir(temp_dir)}\")\n                    errors.append({'file_name': file_name, 'error': 'Download failed - file not found'})\n                    continue\n            \n            file_size_local = os.path.getsize(local_path)\n            print(f\"      ‚úì File downloaded: {file_size_local:,} bytes\")\n            \n            # Extract features\n            features = extractor.extract_all_features(local_path)\n            \n            if features:\n                # Add metadata\n                features['call_id'] = call_id\n                features['agent_id'] = agent_id\n                features['file_name'] = file_name\n                features['file_path'] = stage_path\n                features['file_size_bytes'] = int(row['FILE_SIZE_BYTES'])\n                features['processed_at'] = pd.Timestamp.now()\n                \n                features_list.append(features)\n                print(f\"      ‚úì Features extracted successfully\")\n            else:\n                errors.append({'file_name': file_name, 'error': 'Feature extraction failed'})\n            \n            # Clean up local file to save space\n            try:\n                os.remove(local_path)\n            except:\n                pass\n                \n        except Exception as e:\n            print(f\"      Error: {e}\")\n            errors.append({'file_name': file_name, 'error': str(e)})\n        \n        # Progress update every 10 files\n        if (idx + 1) % 10 == 0:\n            print(f\"\\n   Progress: {idx+1}/{len(audio_files_df)} files processed\\n\")\n    \n    print(f\"\\n   ‚úì Successfully processed {len(features_list)} files\")\n    if errors:\n        print(f\"   ‚ö† {len(errors)} files failed\")\n        print(\"\\n   Failed files:\")\n        for err in errors[:5]:  # Show first 5 errors\n            print(f\"      - {err['file_name']}: {err['error']}\")\n    \n    # Clean up temp directory\n    print(f\"\\n7. Cleaning up temporary directory...\")\n    try:\n        import shutil\n        shutil.rmtree(temp_dir)\n        print(f\"   ‚úì Temporary directory removed\")\n    except Exception as e:\n        print(f\"   Warning: Could not remove temp directory: {e}\")\n    \n    # Step 7: Convert to DataFrame\n    print(\"\\n8. Creating features DataFrame...\")\n    \n    if len(features_list) == 0:\n        print(\"   ‚úó ERROR: No features were extracted successfully!\")\n        print(\"   Please check the error messages above.\")\n        if errors:\n            print(f\"\\n   All {len(errors)} files failed. Sample errors:\")\n            for err in errors[:10]:\n                print(f\"      - {err['file_name']}: {err['error']}\")\n        return None\n    \n    features_pd = pd.DataFrame(features_list)\n    print(f\"   ‚úì Created DataFrame with {len(features_pd)} rows and {len(features_pd.columns)} columns\")\n    \n    # Show sample\n    print(\"\\n   Sample features:\")\n    print(features_pd[['call_id', 'agent_id', 'speaking_rate_wpm', 'interruption_count', 'stress_indicators']].head())\n    \n    # Step 8: Save to Snowflake table\n    print(\"\\n9. Saving features to Snowflake table...\")\n    features_sp = session.create_dataframe(features_pd)\n    features_sp.write.mode('overwrite').save_as_table('BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features')\n    \n    print(\"   ‚úì Features saved to: BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\")\n    \n    # Step 9: Verify saved data\n    print(\"\\n10. Verifying saved data...\")\n    saved_count = session.sql(\"\"\"\n        SELECT COUNT(*) as row_count \n        FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\n    \"\"\").collect()[0]['ROW_COUNT']\n    \n    print(f\"   ‚úì Verified {saved_count} rows in table\")\n    \n    # Show sample from table\n    print(\"\\n   Sample from saved table:\")\n    session.table('BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features').limit(5).show()\n    \n    # Step 10: Summary statistics\n    print(\"\\n11. Summary Statistics:\")\n    \n    # First, check what columns exist\n    print(\"   Checking column names...\")\n    columns_df = session.sql(\"\"\"\n        SELECT * \n        FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features \n        LIMIT 1\n    \"\"\").collect()\n    \n    if columns_df:\n        print(f\"   Available columns: {list(columns_df[0].asDict().keys())[:10]}...\")\n    \n    # Use double quotes to preserve case sensitivity\n    try:\n        summary = session.sql(\"\"\"\n            SELECT \n                COUNT(*) as total_calls,\n                COUNT(DISTINCT \"agent_id\") as unique_agents,\n                ROUND(AVG(\"speaking_rate_wpm\"), 2) as avg_speaking_rate,\n                ROUND(AVG(\"interruption_count\"), 2) as avg_interruptions,\n                ROUND(AVG(\"stress_indicators\"), 3) as avg_stress,\n                ROUND(AVG(\"agent_talk_ratio\"), 3) as avg_agent_talk_ratio\n            FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\n        \"\"\").collect()[0]\n        \n        print(f\"   Total calls processed: {summary['TOTAL_CALLS']}\")\n        print(f\"   Unique agents: {summary['UNIQUE_AGENTS']}\")\n        print(f\"   Avg speaking rate: {summary['AVG_SPEAKING_RATE']} WPM\")\n        print(f\"   Avg interruptions: {summary['AVG_INTERRUPTIONS']}\")\n        print(f\"   Avg stress level: {summary['AVG_STRESS']}\")\n        print(f\"   Avg agent talk ratio: {summary['AVG_AGENT_TALK_RATIO']}\")\n    except Exception as e:\n        print(f\"   Note: Could not compute summary statistics: {e}\")\n        print(\"   You can query the table directly to see the data.\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"PROCESSING COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"\\n‚úì Processed {len(features_list)} audio files\")\n    print(f\"‚úì Extracted {len(features_pd.columns)} features per file\")\n    print(f\"‚úì Saved to table: BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\")\n    print(\"\\nReady for model training!\")\n    \n    return features_sp",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3fda85cb-9c93-4a36-aaf5-9c10ea008b88",
   "metadata": {
    "name": "BUILDING_E_TO_E",
    "collapsed": false
   },
   "source": "## Step 2: Build End-to-End Model\n \nNow we'll use the deployed HuggingFace model to:\n1. Generate acoustic features from call audio\n2. Train an ML model to predict call quality"
  },
  {
   "cell_type": "markdown",
   "id": "1e0dda17-bd34-4cf1-862c-5d8da12166e6",
   "metadata": {
    "name": "GENERATE_FEATURES_FROM_AUDIO",
    "collapsed": false
   },
   "source": "### 2A. Generate Features from Audio"
  },
  {
   "cell_type": "code",
   "id": "1dedebd4-a328-47ee-b0be-09385613a606",
   "metadata": {
    "language": "python",
    "name": "GENERATE_FEATURES"
   },
   "outputs": [],
   "source": "print(f\"\\n‚úì Connected to Snowflake\")\nprint(f\"  Database: {session.get_current_database()}\")\nprint(f\"  Schema: {session.get_current_schema()}\")\nprint(f\"  Warehouse: {session.get_current_warehouse()}\")\n\n# Process all audio files\nfeatures_df = process_stage_audio_files(session)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"You can now use the features for model training:\")\nprint(\"  Table: BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\")\nprint(\"=\"*80)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f23be30b-d2c4-4187-8310-3fba4e708f3f",
   "metadata": {
    "language": "sql",
    "name": "REVIEW_RESULTS"
   },
   "outputs": [],
   "source": "SELECT \n    \"call_id\",\n    \"transcript\",\n    \"dominant_emotion\",\n    \"stress_indicators\",\n    \"interruption_count\"\nFROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\nWHERE \"transcript\" IS NOT NULL \n  AND LENGTH(\"transcript\") > 0\nLIMIT 5;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "564ff34b-721a-4eaa-bbe5-72e872df0c0a",
   "metadata": {
    "language": "sql",
    "name": "USE_AI_TO_ANALYZE_CALL_FEATURES"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE BUILD25_DEV_TO_PRODUCTION.DATA.call_outcomes AS\nWITH analyzed AS (\n    SELECT \n        \"call_id\",\n        \"agent_id\",\n        AI_COMPLETE(\n            'claude-sonnet-4-5',\n            CONCAT(\n                'You are an expert call center quality analyst. Analyze the following customer service call and respond with ONLY a JSON object.\\n\\n',\n                'TRANSCRIPT:\\n', \"transcript\", '\\n\\n',\n                'ACOUSTIC CONTEXT:\\n',\n                '- Dominant emotion: ', \"dominant_emotion\", '\\n',\n                '- Stress level: ', \"stress_indicators\", '\\n',\n                '- Interruptions: ', \"interruption_count\", '\\n\\n',\n                'Based on the transcript and context, return ONLY this JSON (no markdown, no other text):\\n',\n                '{\"call_resolved\": 0 or 1, \"customer_satisfaction_score\": 1-5, \"resolution_confidence\": 0.0-1.0, \"reasoning\": \"explanation\"}\\n\\n',\n                'SCORING:\\n',\n                '- call_resolved: 1 if issue fully resolved, 0 otherwise\\n',\n                '- customer_satisfaction_score: 5=very satisfied, 4=satisfied, 3=neutral, 2=dissatisfied, 1=very dissatisfied\\n',\n                '- resolution_confidence: 0.0 to 1.0\\n',\n                '- reasoning: brief explanation\\n\\n',\n                'Return ONLY the JSON object.'\n            )\n        ) as claude_response\n    FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\n    WHERE \"transcript\" IS NOT NULL \n      AND LENGTH(\"transcript\") > 0\n),\ncleaned AS (\n    SELECT \n        \"call_id\",\n        \"agent_id\",\n        claude_response,\n        TRIM(REPLACE(REPLACE(claude_response, '```json', ''), '```', '')) as cleaned_response\n    FROM analyzed\n),\nparsed AS (\n    SELECT \n        \"call_id\",\n        \"agent_id\",\n        claude_response,\n        cleaned_response,\n        TRY_PARSE_JSON(cleaned_response) as parsed_json\n    FROM cleaned\n)\nSELECT \n    \"call_id\",\n    \"agent_id\",\n    COALESCE(parsed_json:call_resolved::INTEGER, 0) as call_resolved,\n    COALESCE(parsed_json:customer_satisfaction_score::INTEGER, 3) as customer_satisfaction_score,\n    COALESCE(parsed_json:resolution_confidence::FLOAT, 0.5) as resolution_confidence,\n    parsed_json:reasoning::STRING as reasoning,\n    claude_response as raw_response,\n    CURRENT_TIMESTAMP() as analyzed_at\nFROM parsed\nWHERE parsed_json IS NOT NULL;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9cef07c-b243-4618-90d0-8d8287921fc2",
   "metadata": {
    "language": "sql",
    "name": "CHECK_RESULTS"
   },
   "outputs": [],
   "source": "SELECT \n    COUNT(*) as total_calls,\n    SUM(call_resolved) as resolved_calls,\n    ROUND(AVG(call_resolved) * 100, 1) as resolution_rate_pct,\n    ROUND(AVG(customer_satisfaction_score), 2) as avg_satisfaction,\n    ROUND(AVG(resolution_confidence), 3) as avg_confidence,\n    COUNT(CASE WHEN call_resolved = 1 AND customer_satisfaction_score >= 4 THEN 1 END) as high_quality_calls,\n    ROUND(COUNT(CASE WHEN call_resolved = 1 AND customer_satisfaction_score >= 4 THEN 1 END) * 100.0 / COUNT(*), 1) as high_quality_pct\nFROM BUILD25_DEV_TO_PRODUCTION.DATA.call_outcomes;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df05463f-ba4a-4727-aaf3-b48cf2a3c2b1",
   "metadata": {
    "language": "python",
    "name": "TRAIN_MODEL_AND_RUN_EXPERIMENTS"
   },
   "outputs": [],
   "source": "\"\"\"\nSnowflake ML Model Training for Call Quality Prediction\nOptimized for F1 Score with Threshold Tuning\n\"\"\"\n\nimport snowflake.snowpark as snowpark\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.experiment.experiment_tracking import ExperimentTracking\nfrom snowflake.snowpark.functions import col, when, length, regexp_count, random\nfrom datetime import datetime\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve\nimport numpy as np\nimport pandas as pd\n\n# ============================================================================\n# DATA PREPARATION\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"CALL QUALITY PREDICTION - MODEL TRAINING\")\nprint(\"=\"*80)\n\nprint(\"\\n1. Creating training dataset...\")\ntraining_df = session.sql(\"\"\"\n    SELECT \n        f.*,\n        o.call_resolved,\n        o.customer_satisfaction_score,\n        CASE \n            WHEN o.call_resolved = 1 \n                 AND o.customer_satisfaction_score >= 4\n            THEN 1 \n            ELSE 0 \n        END as \"high_quality_call\"\n    FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features f\n    JOIN BUILD25_DEV_TO_PRODUCTION.DATA.call_outcomes o \n        ON f.\"call_id\" = o.\"call_id\"\n\"\"\")\n\nprint(f\"   ‚úì Training dataset size: {training_df.count()} calls\")\n\n# ============================================================================\n# FEATURE DEFINITION\n# ============================================================================\n\nprint(\"\\n2. Defining feature sets...\")\n\nacoustic_features = [\n    '\"speaking_rate_wpm\"',\n    '\"speech_rate_variability\"',\n    '\"avg_pause_duration_sec\"',\n    '\"pause_frequency_per_min\"',\n    '\"avg_pitch_hz\"',\n    '\"pitch_variance\"',\n    '\"pitch_range_hz\"',\n    '\"energy_mean\"',\n    '\"energy_variance\"',\n    '\"dynamic_range_db\"',\n    '\"spectral_centroid\"',\n    '\"harmonics_to_noise_ratio\"',\n    '\"jitter\"',\n    '\"shimmer\"',\n    '\"zero_crossing_rate\"',\n    '\"silence_ratio\"',\n    '\"speech_to_silence_ratio\"'\n]\n\ninteraction_features = [\n    '\"interruption_count\"',\n    '\"agent_talk_ratio\"',\n    '\"turn_taking_rate\"',\n    '\"avg_turn_duration_sec\"'\n]\n\nemotion_features = [\n    '\"avg_emotion_score\"',\n    '\"emotion_volatility\"',\n    '\"stress_indicators\"'\n]\n\nsentiment_features = [\n    '\"sentiment_score\"'\n]\n\nner_features = [\n    '\"word_count\"',\n    '\"entity_count\"'\n]\n\nall_features = acoustic_features + interaction_features + emotion_features + sentiment_features + ner_features\n\nprint(f\"   ‚úì Total features: {len(all_features)}\")\nprint(f\"      - Acoustic: {len(acoustic_features)}\")\nprint(f\"      - Interaction: {len(interaction_features)}\")\nprint(f\"      - Emotion: {len(emotion_features)}\")\nprint(f\"      - Sentiment: {len(sentiment_features)}\")\nprint(f\"      - NER/Content: {len(ner_features)}\")\n\n# ============================================================================\n# DATA SPLITTING\n# ============================================================================\n\nprint(\"\\n3. Splitting data into train/test/holdout sets...\")\n\n# First, separate 5 calls for holdout set (not used in training or testing)\ntraining_df = training_df.with_column(\"random_split\", random())\nholdout_df = training_df.filter(col(\"random_split\") <= 0.05).limit(5)\nremaining_df = training_df.filter(col(\"random_split\") > 0.05)\n\n# Then split remaining into train/test\nremaining_df = remaining_df.with_column(\"random_split2\", random())\ntrain_df = remaining_df.filter(col(\"random_split2\") <= 0.8).drop(\"random_split\", \"random_split2\")\ntest_df = remaining_df.filter(col(\"random_split2\") > 0.8).drop(\"random_split\", \"random_split2\")\nholdout_df = holdout_df.drop(\"random_split\")\n\nprint(f\"   ‚úì Train set: {train_df.count()} calls\")\nprint(f\"   ‚úì Test set: {test_df.count()} calls\")\nprint(f\"   ‚úì Holdout set: {holdout_df.count()} calls (for future validation)\")\n\n# Save holdout call IDs for reference\nholdout_ids = holdout_df.select('\"call_id\"').to_pandas()['call_id'].tolist()\nprint(f\"\\n   üìã Holdout Call IDs (saved for later):\")\nfor i, call_id in enumerate(holdout_ids, 1):\n    print(f\"      {i}. {call_id}\")\n\ntrain_positive = train_df.filter(col('\"high_quality_call\"') == 1).count()\ntrain_total = train_df.count()\ntrain_negative = train_total - train_positive\n\nprint(f\"\\n   üìä Class Distribution:\")\nprint(f\"      Train positive: {train_positive} ({train_positive/train_total:.2%})\")\nprint(f\"      Train negative: {train_negative} ({train_negative/train_total:.2%})\")\n\nif train_positive > 0:\n    scale_pos_weight = train_negative / train_positive\n    print(f\"      Scale pos weight: {scale_pos_weight:.2f}\")\nelse:\n    scale_pos_weight = 1.0\n    print(f\"      ‚ö†Ô∏è  WARNING: No positive examples in training data!\")\n\n# ============================================================================\n# EXPERIMENT TRACKING SETUP\n# ============================================================================\n\nprint(\"\\n4. Setting up experiment tracking...\")\nexp = ExperimentTracking(session=session)\nexp.set_experiment('call_quality_prediction_with_ner')\nprint(\"   ‚úì Experiment: call_quality_prediction_with_ner\")\n\n# ============================================================================\n# HELPER FUNCTION: FIND OPTIMAL THRESHOLD\n# ============================================================================\n\ndef find_optimal_threshold(y_true, y_pred_proba, metric='f1'):\n    \"\"\"Find the threshold that maximizes the specified metric\"\"\"\n    precision, recall, thresholds = precision_recall_curve(y_true, y_pred_proba)\n    \n    if metric == 'f1':\n        # Calculate F1 score for each threshold\n        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)\n        optimal_idx = np.argmax(f1_scores)\n        optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5\n        optimal_score = f1_scores[optimal_idx]\n        metric_name = \"F1\"\n    elif metric == 'recall':\n        # Find threshold that gives good recall while maintaining reasonable precision\n        # Target: Recall > 0.7 and maximize precision\n        valid_indices = recall > 0.7\n        if valid_indices.any():\n            valid_precision = precision[valid_indices]\n            valid_thresholds = thresholds[valid_indices] if sum(valid_indices) <= len(thresholds) else thresholds\n            optimal_idx = np.argmax(valid_precision)\n            optimal_threshold = valid_thresholds[optimal_idx] if len(valid_thresholds) > 0 else 0.3\n            optimal_score = recall[valid_indices][optimal_idx]\n        else:\n            optimal_threshold = 0.3\n            optimal_score = 0.0\n        metric_name = \"Recall\"\n    \n    return optimal_threshold, optimal_score, metric_name\n\n# ============================================================================\n# EXPERIMENT 1: BASELINE WITH OPTIMIZED HYPERPARAMETERS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXPERIMENT 1: Optimized XGBoost with All Features\")\nprint(\"=\"*80)\n\nrun_name_1 = f\"optimized_xgb_all_features_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\nwith exp.start_run(run_name_1) as run:\n    print(f\"\\n‚úì Started run: {run_name_1}\")\n    print(\"Training model...\")\n    \n    model_1 = XGBClassifier(\n        n_estimators=300,\n        max_depth=4,\n        learning_rate=0.03,\n        min_child_weight=1,\n        subsample=0.7,\n        colsample_bytree=0.7,\n        gamma=0.1,\n        reg_alpha=0.1,\n        reg_lambda=1.0,\n        scale_pos_weight=scale_pos_weight * 2,\n        random_state=42,\n        input_cols=all_features,\n        label_cols=['\"high_quality_call\"'],\n        output_cols=['PREDICTION']\n    )\n    \n    model_1.fit(train_df)\n    print(\"   ‚úì Model trained\")\n    \n    predictions_hard = model_1.predict(test_df)\n    predictions_proba = model_1.predict_proba(test_df)\n    print(\"   ‚úì Predictions made\")\n    \n    # Convert everything together to ensure same length\n    test_results = test_df.select(['\"high_quality_call\"']).to_pandas()\n    pred_hard_results = predictions_hard.select(['PREDICTION']).to_pandas()\n    pred_proba_results = predictions_proba.select(['PREDICT_PROBA_1']).to_pandas()\n    \n    # Ensure same length by taking minimum\n    min_len = min(len(test_results), len(pred_hard_results), len(pred_proba_results))\n    y_true = test_results['high_quality_call'].values[:min_len]\n    y_pred_default = pred_hard_results['PREDICTION'].values[:min_len]\n    y_pred_proba = pred_proba_results['PREDICT_PROBA_1'].values[:min_len]\n    \n    print(f\"   ‚úì Using {min_len} samples for evaluation\")\n    \n    # Find optimal threshold\n    optimal_threshold, optimal_f1, metric_name = find_optimal_threshold(y_true, y_pred_proba, metric='f1')\n    print(f\"\\n   üéØ Optimal Threshold: {optimal_threshold:.3f} (maximizes {metric_name})\")\n    \n    # Apply optimal threshold\n    y_pred_optimized = (y_pred_proba >= optimal_threshold).astype(int)\n    \n    # Calculate metrics with default threshold (0.5)\n    accuracy_def = accuracy_score(y_true, y_pred_default)\n    precision_def = precision_score(y_true, y_pred_default, zero_division=0)\n    recall_def = recall_score(y_true, y_pred_default, zero_division=0)\n    f1_def = f1_score(y_true, y_pred_default, zero_division=0)\n    \n    # Calculate metrics with optimized threshold\n    accuracy_opt = accuracy_score(y_true, y_pred_optimized)\n    precision_opt = precision_score(y_true, y_pred_optimized, zero_division=0)\n    recall_opt = recall_score(y_true, y_pred_optimized, zero_division=0)\n    f1_opt = f1_score(y_true, y_pred_optimized, zero_division=0)\n    \n    try:\n        auc = roc_auc_score(y_true, y_pred_proba)\n    except Exception as e:\n        print(f\"   Warning: Could not calculate AUC: {e}\")\n        auc = 0.0\n    \n    print(f\"\\n   üìä Model Performance (Default Threshold = 0.5):\")\n    print(f\"      Accuracy: {accuracy_def:.3f}\")\n    print(f\"      Precision: {precision_def:.3f}\")\n    print(f\"      Recall: {recall_def:.3f}\")\n    print(f\"      F1: {f1_def:.3f}\")\n    \n    print(f\"\\n   üìä Model Performance (Threshold = {optimal_threshold:.3f}):\")\n    print(f\"      Accuracy: {accuracy_opt:.3f}\")\n    print(f\"      Precision: {precision_opt:.3f}\")\n    print(f\"      Recall: {recall_opt:.3f}\")\n    print(f\"      F1: {f1_opt:.3f}\")\n    print(f\"      AUC: {auc:.3f}\")\n    \n    print(f\"\\n   üìà Improvement:\")\n    print(f\"      Accuracy: {accuracy_opt - accuracy_def:+.3f}\")\n    print(f\"      Precision: {precision_opt - precision_def:+.3f}\")\n    print(f\"      Recall: {recall_opt - recall_def:+.3f}\")\n    print(f\"      F1: {f1_opt - f1_def:+.3f}\")\n    \n    exp.log_params({\n        'model_type': 'xgboost_optimized',\n        'n_estimators': 300,\n        'max_depth': 4,\n        'learning_rate': 0.03,\n        'min_child_weight': 1,\n        'subsample': 0.7,\n        'colsample_bytree': 0.7,\n        'gamma': 0.1,\n        'reg_alpha': 0.1,\n        'reg_lambda': 1.0,\n        'scale_pos_weight': scale_pos_weight * 2,\n        'random_state': 42,\n        'feature_source': 'all_features',\n        'feature_count': len(all_features),\n        'optimal_threshold': float(optimal_threshold)\n    })\n    \n    # Log only optimized metrics with plain names\n    exp.log_metrics({\n        'accuracy': accuracy_opt,\n        'precision': precision_opt,\n        'recall': recall_opt,\n        'f1': f1_opt,\n        'auc': auc\n    })\n    print(\"   ‚úì Metrics logged\")\n    \n    try:\n        exp.log_model(model_1, model_name='call_quality_optimized_threshold')\n        print(\"   ‚úì Model logged\")\n    except Exception as e:\n        print(f\"   Warning: Could not log model: {e}\")\n    \n    print(f\"\\n   üíæ Saving optimal threshold: {optimal_threshold:.4f}\")\n    print(f\"   üìù To use this model later, apply threshold: {optimal_threshold:.4f}\")\n    print(f\"   üí° Example: predictions = (probabilities >= {optimal_threshold:.4f}).astype(int)\")\n\nprint(\"‚úì Experiment 1 complete\")\n\n\n# ============================================================================\n# EXPERIMENT 2: ACOUSTIC FEATURES ONLY\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXPERIMENT 2: XGBoost with Acoustic Features Only\")\nprint(\"=\"*80)\n\nrun_name_2 = f\"xgb_acoustic_only_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\nwith exp.start_run(run_name_2) as run:\n    print(f\"\\n‚úì Started run: {run_name_2}\")\n    print(\"Training model...\")\n    \n    acoustic_only_features = acoustic_features + interaction_features\n    \n    # Re-cache test_df to ensure clean state\n    test_df_exp2 = test_df.cache_result()\n    print(f\"   üìä Test set size for this experiment: {test_df_exp2.count()} calls\")\n    \n    model_2 = XGBClassifier(\n        n_estimators=300,\n        max_depth=4,\n        learning_rate=0.03,\n        min_child_weight=1,\n        subsample=0.7,\n        colsample_bytree=0.7,\n        gamma=0.1,\n        reg_alpha=0.1,\n        reg_lambda=1.0,\n        scale_pos_weight=scale_pos_weight * 2,\n        random_state=42,\n        input_cols=acoustic_only_features,\n        label_cols=['\"high_quality_call\"'],\n        output_cols=['PREDICTION']\n    )\n    \n    model_2.fit(train_df)\n    print(\"   ‚úì Model trained\")\n    \n    predictions_hard = model_2.predict(test_df_exp2)\n    predictions_proba = model_2.predict_proba(test_df_exp2)\n    print(\"   ‚úì Predictions made\")\n    \n    test_results = test_df_exp2.select(['\"high_quality_call\"']).to_pandas()\n    pred_proba_results = predictions_proba.select(['PREDICT_PROBA_1']).to_pandas()\n    \n    print(f\"   üìä Lengths: test={len(test_results)}, predictions={len(pred_proba_results)}\")\n    \n    min_len = min(len(test_results), len(pred_proba_results))\n    y_true = test_results['high_quality_call'].values[:min_len]\n    y_pred_proba = pred_proba_results['PREDICT_PROBA_1'].values[:min_len]\n    \n    print(f\"   ‚úì Using {min_len} samples for evaluation\")\n    \n    optimal_threshold, _, _ = find_optimal_threshold(y_true, y_pred_proba, metric='f1')\n    y_pred_optimized = (y_pred_proba >= optimal_threshold).astype(int)\n    \n    accuracy = accuracy_score(y_true, y_pred_optimized)\n    precision = precision_score(y_true, y_pred_optimized, zero_division=0)\n    recall = recall_score(y_true, y_pred_optimized, zero_division=0)\n    f1 = f1_score(y_true, y_pred_optimized, zero_division=0)\n    \n    try:\n        auc = roc_auc_score(y_true, y_pred_proba)\n    except Exception as e:\n        print(f\"   Warning: Could not calculate AUC: {e}\")\n        auc = 0.0\n    \n    print(f\"\\n   üìä Model Performance (Threshold = {optimal_threshold:.3f}):\")\n    print(f\"      Accuracy: {accuracy:.3f}\")\n    print(f\"      Precision: {precision:.3f}\")\n    print(f\"      Recall: {recall:.3f}\")\n    print(f\"      F1: {f1:.3f}\")\n    print(f\"      AUC: {auc:.3f}\")\n    \n    exp.log_params({\n        'model_type': 'xgboost_optimized',\n        'n_estimators': 300,\n        'max_depth': 4,\n        'learning_rate': 0.03,\n        'min_child_weight': 1,\n        'subsample': 0.7,\n        'colsample_bytree': 0.7,\n        'gamma': 0.1,\n        'reg_alpha': 0.1,\n        'reg_lambda': 1.0,\n        'scale_pos_weight': scale_pos_weight * 2,\n        'random_state': 42,\n        'feature_source': 'acoustic_only',\n        'feature_count': len(acoustic_only_features),\n        'optimal_threshold': float(optimal_threshold)\n    })\n    \n    exp.log_metrics({\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'auc': auc\n    })\n    print(\"   ‚úì Metrics logged\")\n    \n    try:\n        exp.log_model(model_2, model_name='call_quality_acoustic_optimized')\n        print(\"   ‚úì Model logged\")\n    except Exception as e:\n        print(f\"   Warning: Could not log model: {e}\")\n\nprint(\"‚úì Experiment 2 complete\")\n\n\n# ============================================================================\n# EXPERIMENT 3: NER + EMOTION FEATURES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXPERIMENT 3: XGBoost with NER + Emotion Features\")\nprint(\"=\"*80)\n\nrun_name_3 = f\"xgb_ner_emotion_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\nwith exp.start_run(run_name_3) as run:\n    print(f\"\\n‚úì Started run: {run_name_3}\")\n    print(\"Training model...\")\n    \n    ner_emotion_features = emotion_features + sentiment_features + ner_features + interaction_features\n    \n    # Re-cache test_df to ensure clean state\n    test_df_exp3 = test_df.cache_result()\n    print(f\"   üìä Test set size for this experiment: {test_df_exp3.count()} calls\")\n    \n    model_3 = XGBClassifier(\n        n_estimators=300,\n        max_depth=4,\n        learning_rate=0.03,\n        min_child_weight=1,\n        subsample=0.7,\n        colsample_bytree=0.7,\n        gamma=0.1,\n        reg_alpha=0.1,\n        reg_lambda=1.0,\n        scale_pos_weight=scale_pos_weight * 2,\n        random_state=42,\n        input_cols=ner_emotion_features,\n        label_cols=['\"high_quality_call\"'],\n        output_cols=['PREDICTION']\n    )\n    \n    model_3.fit(train_df)\n    print(\"   ‚úì Model trained\")\n    \n    predictions_hard = model_3.predict(test_df_exp3)\n    predictions_proba = model_3.predict_proba(test_df_exp3)\n    print(\"   ‚úì Predictions made\")\n    \n    test_results = test_df_exp3.select(['\"high_quality_call\"']).to_pandas()\n    pred_proba_results = predictions_proba.select(['PREDICT_PROBA_1']).to_pandas()\n    \n    print(f\"   üìä Lengths: test={len(test_results)}, predictions={len(pred_proba_results)}\")\n    \n    min_len = min(len(test_results), len(pred_proba_results))\n    y_true = test_results['high_quality_call'].values[:min_len]\n    y_pred_proba = pred_proba_results['PREDICT_PROBA_1'].values[:min_len]\n    \n    print(f\"   ‚úì Using {min_len} samples for evaluation\")\n    \n    optimal_threshold, _, _ = find_optimal_threshold(y_true, y_pred_proba, metric='f1')\n    y_pred_optimized = (y_pred_proba >= optimal_threshold).astype(int)\n    \n    accuracy = accuracy_score(y_true, y_pred_optimized)\n    precision = precision_score(y_true, y_pred_optimized, zero_division=0)\n    recall = recall_score(y_true, y_pred_optimized, zero_division=0)\n    f1 = f1_score(y_true, y_pred_optimized, zero_division=0)\n    \n    try:\n        auc = roc_auc_score(y_true, y_pred_proba)\n    except:\n        auc = 0.0\n    \n    print(f\"\\n   üìä Model Performance (Threshold = {optimal_threshold:.3f}):\")\n    print(f\"      Accuracy: {accuracy:.3f}\")\n    print(f\"      Precision: {precision:.3f}\")\n    print(f\"      Recall: {recall:.3f}\")\n    print(f\"      F1: {f1:.3f}\")\n    print(f\"      AUC: {auc:.3f}\")\n    \n    exp.log_params({\n        'model_type': 'xgboost_optimized',\n        'n_estimators': 300,\n        'max_depth': 4,\n        'learning_rate': 0.03,\n        'min_child_weight': 1,\n        'subsample': 0.7,\n        'colsample_bytree': 0.7,\n        'gamma': 0.1,\n        'reg_alpha': 0.1,\n        'reg_lambda': 1.0,\n        'scale_pos_weight': scale_pos_weight * 2,\n        'random_state': 42,\n        'feature_source': 'ner_emotion_sentiment',\n        'feature_count': len(ner_emotion_features),\n        'optimal_threshold': float(optimal_threshold)\n    })\n    \n    exp.log_metrics({\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'auc': auc\n    })\n    print(\"   ‚úì Metrics logged\")\n    \n    try:\n        exp.log_model(model_3, model_name='call_quality_ner_emotion_optimized')\n        print(\"   ‚úì Model logged\")\n    except Exception as e:\n        print(f\"   Warning: Could not log model: {e}\")\n\nprint(\"‚úì Experiment 3 complete\")\n\n\n# ============================================================================\n# EXPERIMENT 4: SMOTE OVERSAMPLING + ALL FEATURES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXPERIMENT 4: XGBoost with SMOTE Balanced Data\")\nprint(\"=\"*80)\n\nrun_name_4 = f\"xgb_smote_balanced_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\nwith exp.start_run(run_name_4) as run:\n    print(f\"\\n‚úì Started run: {run_name_4}\")\n    print(\"Step 1: Applying SMOTE to balance training data...\")\n    \n    # Convert train_df to pandas for SMOTE\n    train_pd = train_df.select(all_features + ['\"high_quality_call\"']).to_pandas()\n    \n    # Remove quotes from column names in pandas\n    train_pd.columns = [col.strip('\"') for col in train_pd.columns]\n    features_no_quotes = [f.strip('\"') for f in all_features]\n    \n    # Separate features and labels\n    X_train = train_pd[features_no_quotes].values\n    y_train = train_pd['high_quality_call'].values\n    \n    print(f\"   Original training data:\")\n    print(f\"      Positive: {sum(y_train)} ({sum(y_train)/len(y_train):.2%})\")\n    print(f\"      Negative: {len(y_train) - sum(y_train)} ({(len(y_train) - sum(y_train))/len(y_train):.2%})\")\n    \n    # Apply SMOTE\n    smote_applied = False\n    try:\n        from imblearn.over_sampling import SMOTE\n        \n        # Check if we have enough positive samples for SMOTE\n        n_positive = sum(y_train)\n        if n_positive < 6:\n            print(f\"\\n   ‚ö†Ô∏è  WARNING: Only {n_positive} positive samples in training set\")\n            print(f\"   SMOTE requires at least 6 samples. Using k_neighbors={max(1, n_positive - 1)}\")\n            \n            if n_positive < 2:\n                print(f\"   ‚ö†Ô∏è  Cannot apply SMOTE with less than 2 positive samples\")\n                print(f\"   Using original data with increased scale_pos_weight\")\n                train_df_balanced = train_df\n                smote_applied = False\n            else:\n                smote = SMOTE(random_state=42, k_neighbors=min(n_positive - 1, 5))\n                X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n                smote_applied = True\n        else:\n            smote = SMOTE(random_state=42)\n            X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n            smote_applied = True\n        \n        if smote_applied:\n            print(f\"\\n   ‚úì SMOTE applied successfully\")\n            print(f\"   Balanced training data:\")\n            print(f\"      Positive: {sum(y_train_balanced)} ({sum(y_train_balanced)/len(y_train_balanced):.2%})\")\n            print(f\"      Negative: {len(y_train_balanced) - sum(y_train_balanced)} ({(len(y_train_balanced) - sum(y_train_balanced))/len(y_train_balanced):.2%})\")\n            print(f\"      Total samples: {len(y_train_balanced)} (was {len(y_train)})\")\n            \n            # Create balanced dataframe with proper column names for Snowpark\n            balanced_data = {}\n            for i, feature in enumerate(all_features):\n                # Strip quotes and use clean names for pandas\n                clean_name = feature.strip('\"')\n                balanced_data[clean_name] = X_train_balanced[:, i]\n            balanced_data['high_quality_call'] = y_train_balanced\n            \n            # Create pandas DataFrame\n            balanced_df = pd.DataFrame(balanced_data)\n            \n            # Convert back to Snowpark - Snowpark will add proper quoting\n            train_df_balanced = session.create_dataframe(balanced_df)\n            \n            # Rename columns to match original format with quotes\n            for col in balanced_df.columns:\n                train_df_balanced = train_df_balanced.with_column_renamed(col, f'\"{col}\"')\n        \n    except ImportError:\n        print(\"   ‚ö†Ô∏è  WARNING: imbalanced-learn not available, using original data\")\n        print(\"   Install with: pip install imbalanced-learn\")\n        train_df_balanced = train_df\n        smote_applied = False\n    except Exception as e:\n        print(f\"   ‚ö†Ô∏è  WARNING: SMOTE failed with error: {e}\")\n        print(\"   Using original data with increased scale_pos_weight\")\n        train_df_balanced = train_df\n        smote_applied = False\n    \n    print(\"\\nStep 2: Training model on balanced data...\")\n    \n    test_df_exp4 = test_df.cache_result()\n    print(f\"   üìä Test set size for this experiment: {test_df_exp4.count()} calls\")\n    \n    # Adjust scale_pos_weight based on whether SMOTE was applied\n    if smote_applied:\n        scale_weight = 1.0  # Data is balanced\n    else:\n        scale_weight = scale_pos_weight * 3  # Increase weight if SMOTE failed\n    \n    model_4 = XGBClassifier(\n        n_estimators=300,\n        max_depth=4,\n        learning_rate=0.03,\n        min_child_weight=1,\n        subsample=0.7,\n        colsample_bytree=0.7,\n        gamma=0.1,\n        reg_alpha=0.1,\n        reg_lambda=1.0,\n        scale_pos_weight=scale_weight,\n        random_state=42,\n        input_cols=all_features,\n        label_cols=['\"high_quality_call\"'],\n        output_cols=['PREDICTION']\n    )\n    \n    model_4.fit(train_df_balanced)\n    print(\"   ‚úì Model trained\")\n    \n    predictions_hard = model_4.predict(test_df_exp4)\n    predictions_proba = model_4.predict_proba(test_df_exp4)\n    print(\"   ‚úì Predictions made\")\n    \n    test_results = test_df_exp4.select(['\"high_quality_call\"']).to_pandas()\n    pred_proba_results = predictions_proba.select(['PREDICT_PROBA_1']).to_pandas()\n    \n    print(f\"   üìä Lengths: test={len(test_results)}, predictions={len(pred_proba_results)}\")\n    \n    min_len = min(len(test_results), len(pred_proba_results))\n    y_true = test_results['high_quality_call'].values[:min_len]\n    y_pred_proba = pred_proba_results['PREDICT_PROBA_1'].values[:min_len]\n    \n    print(f\"   ‚úì Using {min_len} samples for evaluation\")\n    \n    optimal_threshold, _, _ = find_optimal_threshold(y_true, y_pred_proba, metric='f1')\n    y_pred_optimized = (y_pred_proba >= optimal_threshold).astype(int)\n    \n    accuracy = accuracy_score(y_true, y_pred_optimized)\n    precision = precision_score(y_true, y_pred_optimized, zero_division=0)\n    recall = recall_score(y_true, y_pred_optimized, zero_division=0)\n    f1 = f1_score(y_true, y_pred_optimized, zero_division=0)\n    \n    try:\n        auc = roc_auc_score(y_true, y_pred_proba)\n    except:\n        auc = 0.0\n    \n    print(f\"\\n   üìä Model Performance (Threshold = {optimal_threshold:.3f}):\")\n    print(f\"      Accuracy: {accuracy:.3f}\")\n    print(f\"      Precision: {precision:.3f}\")\n    print(f\"      Recall: {recall:.3f}\")\n    print(f\"      F1: {f1:.3f}\")\n    print(f\"      AUC: {auc:.3f}\")\n    \n    exp.log_params({\n        'model_type': 'xgboost_optimized_smote',\n        'n_estimators': 300,\n        'max_depth': 4,\n        'learning_rate': 0.03,\n        'min_child_weight': 1,\n        'subsample': 0.7,\n        'colsample_bytree': 0.7,\n        'gamma': 0.1,\n        'reg_alpha': 0.1,\n        'reg_lambda': 1.0,\n        'scale_pos_weight': scale_weight,\n        'random_state': 42,\n        'feature_source': 'all_features_smote_balanced',\n        'feature_count': len(all_features),\n        'smote_applied': smote_applied,\n        'optimal_threshold': float(optimal_threshold)\n    })\n    \n    exp.log_metrics({\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'auc': auc\n    })\n    print(\"   ‚úì Metrics logged\")\n    \n    try:\n        exp.log_model(model_4, model_name='call_quality_smote_balanced')\n        print(\"   ‚úì Model logged\")\n    except Exception as e:\n        print(f\"   Warning: Could not log model: {e}\")\n\nprint(\"‚úì Experiment 4 complete\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ALL EXPERIMENTS COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"\\n‚úì Trained 4 models with threshold optimization\")\nprint(f\"‚úì Experiment: call_quality_prediction_with_ner\")\nprint(f\"\\nModels saved:\")\nprint(f\"   1. call_quality_optimized_threshold ({len(all_features)} features)\")\nprint(f\"   2. call_quality_acoustic_optimized ({len(acoustic_features + interaction_features)} features)\")\nprint(f\"   3. call_quality_ner_emotion_optimized ({len(ner_emotion_features)} features)\")\nprint(f\"   4. call_quality_smote_balanced ({len(all_features)} features, SMOTE balanced)\")\nprint(\"\\nüìä KEY OPTIMIZATIONS:\")\nprint(f\"   ‚úÖ Optimized hyperparameters for better generalization\")\nprint(f\"   ‚úÖ Doubled scale_pos_weight for class imbalance\")\nprint(f\"   ‚úÖ Automatic threshold tuning to maximize F1 score\")\nprint(f\"   ‚úÖ Comparison of default vs optimized threshold performance\")\nprint(f\"   ‚úÖ SMOTE oversampling for balanced training data\")\nprint(f\"\\nüíæ SAVED FOR PRODUCTION:\")\nprint(f\"   ‚úÖ Optimal thresholds logged as parameters in each experiment\")\nprint(f\"   ‚úÖ {len(holdout_ids)} holdout call IDs reserved for final validation\")\nprint(f\"   ‚úÖ Retrieve threshold from experiment params when deploying\")\nprint(\"\\nüìã Holdout Call IDs (for final validation):\")\nfor i, call_id in enumerate(holdout_ids, 1):\n    print(f\"   {i}. {call_id}\")\nprint(\"=\"*80)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5302093d-fe7d-465e-840c-527872939618",
   "metadata": {
    "language": "python",
    "name": "DEPLOY_OUR_MODEL"
   },
   "outputs": [],
   "source": "# ============================================================================\n# FIND AND ACCESS THE REGISTERED MODEL\n# ============================================================================\n\nfrom snowflake.ml.registry import Registry\n\nprint(\"=\"*80)\nprint(\"FINDING REGISTERED MODEL\")\nprint(\"=\"*80)\n\n# ============================================================================\n# STEP 1: Check current context\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 1: Current Context\")\nprint(\"=\"*80)\n\ncurrent_db = session.sql(\"SELECT CURRENT_DATABASE()\").collect()[0][0]\ncurrent_schema = session.sql(\"SELECT CURRENT_SCHEMA()\").collect()[0][0]\n\nprint(f\"   Current Database: {current_db}\")\nprint(f\"   Current Schema: {current_schema}\")\n\n# ============================================================================\n# STEP 2: Find where models are registered\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 2: Finding Registered Models\")\nprint(\"=\"*80)\n\n# Check in NOTEBOOK schema\nprint(\"\\nüì¶ Checking NOTEBOOK schema...\")\ntry:\n    session.sql(\"USE SCHEMA BUILD25_DEV_TO_PRODUCTION.NOTEBOOK\").collect()\n    registry_notebook = Registry(session=session)\n    \n    models_notebook = registry_notebook.show_models()\n    \n    if len(models_notebook) > 0:\n        print(f\"   ‚úì Found {len(models_notebook)} model(s) in NOTEBOOK schema:\")\n        models_notebook.show()\n        \n        # Check for our specific model\n        model_names = [row['name'] for row in models_notebook.collect()]\n        if 'call_quality_smote_balanced' in model_names:\n            print(f\"   ‚úÖ Found 'call_quality_smote_balanced' in NOTEBOOK schema!\")\n            model_schema = \"NOTEBOOK\"\n        else:\n            print(f\"   Available models: {model_names}\")\n    else:\n        print(f\"   No models in NOTEBOOK schema\")\n        \nexcept Exception as e:\n    print(f\"   Error: {e}\")\n\n# Check in DATA schema\nprint(\"\\nüì¶ Checking DATA schema...\")\ntry:\n    session.sql(\"USE SCHEMA BUILD25_DEV_TO_PRODUCTION.DATA\").collect()\n    registry_data = Registry(session=session)\n    \n    models_data = registry_data.show_models()\n    \n    if len(models_data) > 0:\n        print(f\"   ‚úì Found {len(models_data)} model(s) in DATA schema:\")\n        models_data.show()\n        \n        model_names = [row['name'] for row in models_data.collect()]\n        if 'call_quality_smote_balanced' in model_names:\n            print(f\"   ‚úÖ Found 'call_quality_smote_balanced' in DATA schema!\")\n            model_schema = \"DATA\"\n        else:\n            print(f\"   Available models: {model_names}\")\n    else:\n        print(f\"   No models in DATA schema\")\n        \nexcept Exception as e:\n    print(f\"   Error: {e}\")\n\n# ============================================================================\n# STEP 3: Use the correct schema and load model\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 3: Loading Model from Correct Schema\")\nprint(\"=\"*80)\n\n# The model is likely in NOTEBOOK schema (where training happened)\ntry:\n    session.sql(\"USE SCHEMA BUILD25_DEV_TO_PRODUCTION.NOTEBOOK\").collect()\n    print(f\"‚úì Switched to NOTEBOOK schema\")\n    \n    registry = Registry(session=session)\n    model_ref = registry.get_model('call_quality_smote_balanced')\n    mv = model_ref.default\n    \n    print(f\"‚úÖ Model loaded successfully from NOTEBOOK schema!\")\n    print(f\"   Model: call_quality_smote_balanced\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error loading model: {e}\")\n    \n    # Show all available models\n    print(\"\\nüìã All available models:\")\n    try:\n        all_models = registry.show_models()\n        all_models.show()\n    except:\n        print(\"   Could not list models\")\n    \n    raise\n\n# ============================================================================\n# STEP 4: Deploy service to DATA schema\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 4: Deploying Service to DATA Schema\")\nprint(\"=\"*80)\n\nservice_name = \"call_quality_prediction_service\"\ncompute_pool_name = \"SYSTEM_COMPUTE_POOL_GPU\"\n\n# Even though model is in NOTEBOOK, we can deploy service to DATA schema\n# by switching context before deployment\n\n# First, drop any existing services\nprint(\"\\n   Cleaning up existing services...\")\n\nfor schema in ['NOTEBOOK', 'DATA']:\n    try:\n        session.sql(f\"\"\"\n            DROP SERVICE IF EXISTS BUILD25_DEV_TO_PRODUCTION.{schema}.{service_name}\n        \"\"\").collect()\n        print(f\"   ‚úì Dropped from {schema}\")\n    except:\n        pass\n\nimport time\ntime.sleep(3)\n\n# Switch to DATA schema for deployment\nsession.sql(\"USE SCHEMA BUILD25_DEV_TO_PRODUCTION.DATA\").collect()\nprint(f\"\\n‚úì Switched to DATA schema for deployment\")\n\n# Deploy the service\nprint(f\"\\n‚è≥ Deploying service...\")\n\ntry:\n    deployment = mv.create_service(\n        service_name=service_name,\n        service_compute_pool=compute_pool_name,\n        max_instances=1,\n        force_rebuild=True\n    )\n    \n    print(f\"\\n‚úÖ Service deployed successfully!\")\n    print(f\"   Service: BUILD25_DEV_TO_PRODUCTION.DATA.{service_name}\")\n    print(f\"   Model source: BUILD25_DEV_TO_PRODUCTION.NOTEBOOK.call_quality_smote_balanced\")\n    \nexcept Exception as e:\n    print(f\"\\n‚ùå Deployment failed: {e}\")\n    \n    # Try deploying to NOTEBOOK schema instead\n    print(f\"\\n   Trying deployment to NOTEBOOK schema...\")\n    \n    try:\n        session.sql(\"USE SCHEMA BUILD25_DEV_TO_PRODUCTION.NOTEBOOK\").collect()\n        \n        deployment = mv.create_service(\n            service_name=service_name,\n            service_compute_pool=compute_pool_name,\n            max_instances=1,\n            force_rebuild=True\n        )\n        \n        print(f\"\\n‚úÖ Service deployed to NOTEBOOK schema!\")\n        print(f\"   Service: BUILD25_DEV_TO_PRODUCTION.NOTEBOOK.{service_name}\")\n        \n    except Exception as e2:\n        print(f\"\\n‚ùå Alternative also failed: {e2}\")\n        raise\n\n# ============================================================================\n# STEP 5: Verify deployment\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 5: Verifying Deployment\")\nprint(\"=\"*80)\n\ntime.sleep(3)\n\nprint(\"\\nüìä All services in database:\")\ntry:\n    all_services = session.sql(\"\"\"\n        SHOW SERVICES IN DATABASE BUILD25_DEV_TO_PRODUCTION\n    \"\"\").collect()\n    \n    for svc in all_services:\n        schema = svc['schema_name']\n        status_icon = \"‚úÖ\" if svc['state'] == 'READY' else \"‚è≥\" if svc['state'] == 'STARTING' else \"‚ùå\"\n        print(f\"   {status_icon} {schema}.{svc['name']} - State: {svc['state']}\")\n        \nexcept Exception as e:\n    print(f\"   Note: {e}\")\n\n# ============================================================================\n# STEP 6: Wait for service\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 6: Waiting for Service to be Ready\")\nprint(\"=\"*80)\n\nmax_checks = 12\nservice_ready = False\nservice_schema = None\n\nfor i in range(max_checks):\n    try:\n        # Check in both schemas\n        for schema in ['DATA', 'NOTEBOOK']:\n            status = session.sql(f\"\"\"\n                SHOW SERVICES LIKE '{service_name}' IN SCHEMA BUILD25_DEV_TO_PRODUCTION.{schema}\n            \"\"\").collect()\n            \n            if status:\n                state = status[0]['state']\n                service_schema = schema\n                elapsed = i * 15\n                print(f\"   [{elapsed}s] {schema}: {state}\")\n                \n                if state == 'READY':\n                    print(f\"\\n‚úÖ Service is READY in {schema} schema!\")\n                    service_ready = True\n                    break\n                elif state in ['FAILED', 'ERROR']:\n                    print(f\"\\n‚ùå Service failed in {schema}: {state}\")\n                    break\n        \n        if service_ready:\n            break\n            \n    except Exception as e:\n        pass\n    \n    if i < max_checks - 1:\n        time.sleep(15)\n\n# ============================================================================\n# SUMMARY\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ SETUP COMPLETE\")\nprint(\"=\"*80)\n\nprint(f\"\"\"\nüìä Summary:\n   Model Location: BUILD25_DEV_TO_PRODUCTION.NOTEBOOK.call_quality_smote_balanced\n   Service Location: BUILD25_DEV_TO_PRODUCTION.{service_schema if service_schema else 'TBD'}.{service_name}\n   Service Status: {'‚úÖ READY' if service_ready else '‚è≥ Check manually'}\n   \nüìù To make predictions, use:\n   \n   SELECT \n       \"call_id\",\n       BUILD25_DEV_TO_PRODUCTION.{service_schema if service_schema else '[SCHEMA]'}.{service_name}!PREDICT(*) as prediction\n   FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\n   WHERE \"call_id\" = 'your-call-id'\n   LIMIT 5;\n\n\"\"\")\n\nprint(\"=\"*80)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2f2bc509-9c48-414d-a4a8-4767e63f0a61",
   "metadata": {
    "language": "python",
    "name": "MAKE_OUR_PERDICTIONS"
   },
   "outputs": [],
   "source": "# ============================================================================\n# MAKE PREDICTIONS USING mv.run() METHOD\n# ============================================================================\n\nimport snowflake.snowpark as snowpark\nfrom snowflake.ml.registry import Registry\nfrom snowflake.snowpark.functions import col, when, lit, current_timestamp\n\nprint(\"=\"*80)\nprint(\"MAKE PREDICTIONS USING MODEL VERSION\")\nprint(\"=\"*80)\n\n# ============================================================================\n# STEP 1: Load Model Version\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 1: Loading Model\")\nprint(\"=\"*80)\n\n# Initialize registry with correct schema\nreg = Registry(\n    session=session, \n    database_name='BUILD25_DEV_TO_PRODUCTION', \n    schema_name='NOTEBOOK'\n)\n\nprint(\"‚úì Registry initialized\")\nprint(\"   Database: BUILD25_DEV_TO_PRODUCTION\")\nprint(\"   Schema: NOTEBOOK\")\n\n# Get the specific model version\ntry:\n    mv = reg.get_model('CALL_QUALITY_SMOTE_BALANCED').version('SERIOUS_INSECT_1')\n    print(\"\\n‚úÖ Model version loaded:\")\n    print(\"   Model: CALL_QUALITY_SMOTE_BALANCED\")\n    print(\"   Version: SERIOUS_INSECT_1\")\nexcept Exception as e:\n    print(f\"\\n‚ùå Error loading model: {e}\")\n    \n    # Show available models\n    print(\"\\nüì¶ Available models:\")\n    try:\n        models = reg.show_models()\n        models.show()\n    except:\n        pass\n    \n    raise\n\n# ============================================================================\n# STEP 2: Load Your 5 Calls\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 2: Loading Target Calls\")\nprint(\"=\"*80)\n\ncall_ids = [\n    '0724ec7f-da66-420a-bfdf-925247fd9041',\n    '09f444c8-b316-4094-a088-aafdb8269c55',\n    '196d451b-ab6d-4863-9b5e-659089ccb58c',\n    '1b8cb9f5-948a-4aed-b170-8e2b64cb3931',\n    '20d3da90-c70b-47f7-a57b-f95139a1fd63'\n]\n\ncall_ids_str = \"', '\".join(call_ids)\n\nprint(f\"üìã Target: {len(call_ids)} calls\\n\")\n\n# Load the input data\ninput_dataframe = session.sql(f\"\"\"\n    SELECT \n        f.*,\n        o.call_resolved,\n        o.customer_satisfaction_score,\n        CASE \n            WHEN o.call_resolved = 1 AND o.customer_satisfaction_score >= 4\n            THEN 1 \n            ELSE 0 \n        END as \"actual_high_quality_call\"\n    FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features f\n    LEFT JOIN BUILD25_DEV_TO_PRODUCTION.DATA.call_outcomes o \n        ON f.\"call_id\" = o.\"call_id\"\n    WHERE f.\"call_id\" IN ('{call_ids_str}')\n\"\"\")\n\ncall_count = input_dataframe.count()\nprint(f\"‚úì Loaded {call_count} calls\")\n\nif call_count == 0:\n    print(\"‚ùå No calls found!\")\n    raise Exception(\"No calls found with these IDs\")\n\n# Show sample\nprint(\"\\nüìã Sample input data:\")\ninput_dataframe.select(\n    '\"call_id\"',\n    '\"speaking_rate_wpm\"',\n    '\"avg_emotion_score\"',\n    '\"sentiment_score\"',\n    '\"actual_high_quality_call\"'\n).show(3)\n\n# ============================================================================\n# STEP 3: Make Predictions Using Service\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 3: Making Predictions\")\nprint(\"=\"*80)\n\nservice_name = 'CALL_QUALITY_PREDICTION_SERVICE'\n\nprint(f\"üîÑ Running predictions...\")\nprint(f\"   Service: {service_name}\")\nprint(f\"   Function: PREDICT\")\n\npredictions = None\n\ntry:\n    # Use mv.run() with the service\n    predictions = mv.run(\n        input_dataframe, \n        function_name='PREDICT',\n        service_name=service_name\n    )\n    \n    print(\"‚úÖ Predictions completed!\")\n    \nexcept Exception as e:\n    error_msg = str(e)\n    print(f\"‚ùå Error with PREDICT: {error_msg[:300]}\")\n    \n    # Try PREDICT_PROBA\n    print(\"\\n   Trying PREDICT_PROBA...\")\n    try:\n        predictions = mv.run(\n            input_dataframe, \n            function_name='PREDICT_PROBA',\n            service_name=service_name\n        )\n        print(\"‚úÖ PREDICT_PROBA worked!\")\n        \n    except Exception as e2:\n        print(f\"‚ùå PREDICT_PROBA also failed: {str(e2)[:300]}\")\n        \n        # Try without service_name (use default)\n        print(\"\\n   Trying default service...\")\n        try:\n            predictions = mv.run(\n                input_dataframe, \n                function_name='PREDICT'\n            )\n            print(\"‚úÖ Default service worked!\")\n        except Exception as e3:\n            print(f\"‚ùå All methods failed: {str(e3)[:300]}\")\n            raise\n\nif predictions is None:\n    print(\"\\n‚ùå Could not make predictions\")\n    raise Exception(\"Prediction failed\")\n\n# ============================================================================\n# STEP 4: Display Results\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 4: Prediction Results\")\nprint(\"=\"*80)\n\nprint(\"\\nüìä Raw Predictions:\")\npredictions.show()\n\n# Show column names\nprint(\"\\nüìã Output columns:\")\nfor col_name in predictions.columns:\n    print(f\"   - {col_name}\")\n\n# Convert to pandas for detailed analysis\nresults_pd = predictions.to_pandas()\n\nprint(f\"\\n‚úì Got {len(results_pd)} predictions\")\n\n# Detailed results\nprint(\"\\nüìä Detailed Results:\\n\")\n\ncorrect_count = 0\n\nfor idx, row in results_pd.iterrows():\n    call_id = row.get('call_id', 'Unknown')\n    call_id_short = call_id[:8] + \"...\" if len(call_id) > 8 else call_id\n    \n    # Find prediction column\n    pred_cols = [c for c in results_pd.columns if 'PREDICTION' in c.upper() or 'OUTPUT' in c.upper()]\n    \n    if pred_cols:\n        pred_col = pred_cols[0]\n        pred_value = row[pred_col]\n        \n        actual_value = row.get('actual_high_quality_call', 'N/A')\n        \n        is_correct = str(pred_value) == str(actual_value)\n        if is_correct:\n            correct_count += 1\n        \n        match_icon = \"‚úÖ\" if is_correct else \"‚ùå\"\n        \n        print(f\"{match_icon} Call {idx+1}: {call_id_short}\")\n        print(f\"   Predicted:    {pred_value}\")\n        print(f\"   Actual:       {actual_value}\")\n        print(f\"   Resolved:     {row.get('call_resolved', 'N/A')}\")\n        print(f\"   Satisfaction: {row.get('customer_satisfaction_score', 'N/A')}\")\n        print()\n\naccuracy = correct_count / len(results_pd) if len(results_pd) > 0 else 0\nprint(f\"üìà Accuracy: {correct_count}/{len(results_pd)} ({accuracy*100:.1f}%)\")\n\n# ============================================================================\n# STEP 5: Save for Monitoring\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STEP 5: Saving for Monitoring\")\nprint(\"=\"*80)\n\ntry:\n    optimal_threshold = 0.45\n    \n    # Add metadata columns\n    predictions_with_meta = predictions.with_column(\n        'TIMESTAMP',\n        current_timestamp()\n    ).with_column(\n        'model_threshold',\n        lit(optimal_threshold)\n    ).with_column(\n        'model_name',\n        lit('CALL_QUALITY_SMOTE_BALANCED')\n    ).with_column(\n        'model_version',\n        lit('SERIOUS_INSECT_1')\n    ).with_column(\n        'service_name',\n        lit(service_name)\n    )\n    \n    # Find prediction column\n    pred_cols = [c for c in predictions_with_meta.columns if 'PREDICTION' in c.upper()]\n    pred_col_name = pred_cols[0] if pred_cols else 'PREDICTION'\n    \n    # Format for monitoring\n    monitoring_df = predictions_with_meta.select(\n        col('\"call_id\"').alias('ID'),\n        col('TIMESTAMP'),\n        col(pred_col_name).alias('OUTPUT_ENCODED'),\n        col('\"actual_high_quality_call\"').alias('LABEL_ENCODED'),\n        col('model_threshold'),\n        col('model_name'),\n        col('model_version'),\n        col('service_name')\n    )\n    \n    # Save\n    monitoring_df.write.mode('overwrite').save_as_table(\n        'BUILD25_DEV_TO_PRODUCTION.DATA.call_quality_predictions_monitored'\n    )\n    \n    print(\"‚úÖ Saved to: BUILD25_DEV_TO_PRODUCTION.DATA.call_quality_predictions_monitored\")\n    \n    # Verify\n    saved_count = session.sql(\"\"\"\n        SELECT COUNT(*) as cnt \n        FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_quality_predictions_monitored\n    \"\"\").collect()[0]['CNT']\n    \n    print(f\"‚úì Table contains {saved_count} records\")\n    \n    # Show sample\n    print(\"\\nüìã Sample from monitoring table:\")\n    session.sql(\"\"\"\n        SELECT * \n        FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_quality_predictions_monitored\n        LIMIT 3\n    \"\"\").show()\n    \nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Error saving: {e}\")\n    print(\"   Predictions were made but couldn't save to monitoring table\")\n\n# ============================================================================\n# SUMMARY\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ PREDICTIONS COMPLETE!\")\nprint(\"=\"*80)\n\nprint(f\"\"\"\nüìä Summary:\n   ‚úì Model: CALL_QUALITY_SMOTE_BALANCED\n   ‚úì Version: SERIOUS_INSECT_1\n   ‚úì Service: {service_name}\n   ‚úì Method: mv.run()\n   \n   ‚úì Predictions: {call_count} calls\n   ‚úì Accuracy: {accuracy*100:.1f}%\n   ‚úì Saved to: call_quality_predictions_monitored\n\nüìù Next Step:\n   Run the monitoring setup script to create the model monitor!\n\nüí° What we did:\n   1. Loaded model version from registry\n   2. Used mv.run() with service name\n   3. Made predictions on 5 calls\n   4. Saved results for monitoring\n\n\"\"\")\n\nprint(\"=\"*80)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d564b3d8-1092-4981-a1c8-2dcdcdf37835",
   "metadata": {
    "language": "sql",
    "name": "ADD_MONITORING"
   },
   "outputs": [],
   "source": "USE ROLE ACCOUNTADMIN;\nUSE DATABASE BUILD25_DEV_TO_PRODUCTION;\nUSE SCHEMA DATA;\n\n-- Recreate the baseline using the NTZ view/column names\nCREATE OR REPLACE TABLE call_quality_baseline AS\nSELECT\n  ID,                                -- keep as-is (matches source)\n  event_time_ntz,                    -- NTZ timestamp (matches source)\n  OUTPUT_ENCODED,                    -- keep as-is unless you see a type mismatch\n  CAST(LABEL_ENCODED AS NUMBER(38,0)) AS LABEL_ENCODED  -- <-- fix here\nFROM BUILD25_DEV_TO_PRODUCTION.DATA.call_quality_predictions_monitored_ntz\nORDER BY event_time_ntz DESC\nLIMIT 100;\n\nUSE SCHEMA NOTEBOOK;\n\nDROP MODEL MONITOR IF EXISTS call_quality_monitor;\n\nCREATE MODEL MONITOR call_quality_monitor\nWITH\n    MODEL = \"CALL_QUALITY_SMOTE_BALANCED\"\n    VERSION = 'SERIOUS_INSECT_1'\n    FUNCTION = 'PREDICT'\n    SOURCE = BUILD25_DEV_TO_PRODUCTION.DATA.call_quality_predictions_monitored_ntz\n    BASELINE = BUILD25_DEV_TO_PRODUCTION.DATA.call_quality_baseline\n    TIMESTAMP_COLUMN = event_time_ntz\n    ID_COLUMNS = ('ID')\n    PREDICTION_CLASS_COLUMNS = ('OUTPUT_ENCODED')\n    ACTUAL_CLASS_COLUMNS = ('LABEL_ENCODED')\n    WAREHOUSE = JAMES_XS\n    REFRESH_INTERVAL = '1 hour'\n    AGGREGATION_WINDOW = '1 day';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eabfb57a-078a-4b50-b657-abcc5177201b",
   "metadata": {
    "language": "python",
    "name": "SETUP_ONLINE_FEATURE_STORE",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "\"\"\"\nSetup Online Feature Store\nCreates feature views, waits for materialization, then enables online serving\n\"\"\"\n\nimport snowflake.snowpark as snowpark\nfrom snowflake.ml.feature_store import FeatureStore, Entity, OnlineConfig\nfrom snowflake.ml.feature_store.feature_view import FeatureView, StoreType\nfrom snowflake.snowpark.functions import col\nimport time\n\ncurrent_warehouse = session.get_current_warehouse()\n\nprint(\"=\"*80)\nprint(\"ONLINE FEATURE STORE SETUP - PROPER ORDER\")\nprint(\"=\"*80)\n\n# ============================================================================\n# PHASE 1: Setup Offline First (Dynamic Tables)\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 1: CREATE FEATURE VIEWS WITH ONLINE CONFIG\")\nprint(\"=\"*80)\n\nprint(\"\\n1. Creating/connecting to Feature Store...\")\nfs = FeatureStore(\n    session=session,\n    database=\"BUILD25_DEV_TO_PRODUCTION\",\n    name=\"CALL_QUALITY_FS\",\n    default_warehouse=current_warehouse,\n    creation_mode=\"create_if_not_exist\"\n)\nprint(\"   ‚úì Feature Store ready\")\n\nprint(\"\\n2. Registering entity...\")\ntry:\n    call_entity = Entity(\n        name=\"call\",\n        join_keys=[\"call_id\"],\n        desc=\"Individual customer service call\"\n    )\n    call_entity = fs.register_entity(call_entity)\n    print(\"   ‚úì Entity registered\")\nexcept Exception as e:\n    call_entity = fs.get_entity(\"call\")\n    print(\"   ‚úì Entity exists\")\n\nprint(\"\\n3. Creating feature views WITH online config from start...\")\n\n# Acoustic Features\nprint(\"   Creating acoustic_features with online serving...\")\nsession.use_schema('CALL_QUALITY_FS')\n\nacoustic_df = session.sql(\"\"\"\n    SELECT \n        \"call_id\" as call_id,\n        \"speaking_rate_wpm\" as speaking_rate_wpm,\n        \"speech_rate_variability\" as speech_rate_variability,\n        \"avg_pause_duration_sec\" as avg_pause_duration_sec,\n        \"pause_frequency_per_min\" as pause_frequency_per_min,\n        \"avg_pitch_hz\" as avg_pitch_hz,\n        \"pitch_variance\" as pitch_variance,\n        \"pitch_range_hz\" as pitch_range_hz,\n        \"energy_mean\" as energy_mean,\n        \"energy_variance\" as energy_variance,\n        \"dynamic_range_db\" as dynamic_range_db,\n        \"spectral_centroid\" as spectral_centroid,\n        \"harmonics_to_noise_ratio\" as harmonics_to_noise_ratio,\n        \"jitter\" as jitter,\n        \"shimmer\" as shimmer,\n        \"zero_crossing_rate\" as zero_crossing_rate,\n        \"silence_ratio\" as silence_ratio,\n        \"speech_to_silence_ratio\" as speech_to_silence_ratio,\n        \"interruption_count\" as interruption_count,\n        \"agent_talk_ratio\" as agent_talk_ratio,\n        \"turn_taking_rate\" as turn_taking_rate,\n        \"avg_turn_duration_sec\" as avg_turn_duration_sec,\n        \"processed_at\" as timestamp_col\n    FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\n\"\"\")\n\nacoustic_fv = FeatureView(\n    name=\"acoustic_features\",\n    entities=[call_entity],\n    feature_df=acoustic_df,\n    timestamp_col=\"timestamp_col\",\n    refresh_freq=\"1 minute\",\n    refresh_mode=\"INCREMENTAL\",\n    desc=\"Acoustic features for agent coaching\",\n    online_config=OnlineConfig(enable=True, target_lag=\"30 seconds\")\n)\n\ntry:\n    acoustic_fv = fs.register_feature_view(\n        feature_view=acoustic_fv,\n        version=\"v1\",\n        overwrite=True\n    )\n    print(\"      ‚úì acoustic_features created with online serving\")\nexcept Exception as e:\n    print(f\"      ‚úó Error: {e}\")\n    print(f\"         This may be because online config is in the constructor now\")\n\n# Emotion & Sentiment Features\nprint(\"   Creating emotion_sentiment_features with online serving...\")\nemotion_df = session.sql(\"\"\"\n    SELECT \n        \"call_id\" as call_id,\n        \"avg_emotion_score\" as avg_emotion_score,\n        \"emotion_volatility\" as emotion_volatility,\n        \"stress_indicators\" as stress_indicators,\n        \"sentiment_score\" as sentiment_score,\n        \"sentiment_label\" as sentiment_label,\n        \"dominant_emotion\" as dominant_emotion,\n        \"processed_at\" as timestamp_col\n    FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\n\"\"\")\n\nemotion_fv = FeatureView(\n    name=\"emotion_sentiment_features\",\n    entities=[call_entity],\n    feature_df=emotion_df,\n    timestamp_col=\"timestamp_col\",\n    refresh_freq=\"1 minute\",\n    refresh_mode=\"INCREMENTAL\",\n    desc=\"Emotion and sentiment features\",\n    online_config=OnlineConfig(enable=True, target_lag=\"30 seconds\")\n)\n\ntry:\n    emotion_fv = fs.register_feature_view(\n        feature_view=emotion_fv,\n        version=\"v1\",\n        overwrite=True\n    )\n    print(\"      ‚úì emotion_sentiment_features created with online serving\")\nexcept Exception as e:\n    print(f\"      ‚úó Error: {e}\")\n\n# NER & Content Features\nprint(\"   Creating ner_content_features with online serving...\")\nner_df = session.sql(\"\"\"\n    SELECT \n        \"call_id\" as call_id,\n        \"word_count\" as word_count,\n        \"entity_count\" as entity_count,\n        \"entities_person\" as entities_person,\n        \"entities_org\" as entities_org,\n        \"entities_loc\" as entities_loc,\n        \"processed_at\" as timestamp_col\n    FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\n\"\"\")\n\nner_fv = FeatureView(\n    name=\"ner_content_features\",\n    entities=[call_entity],\n    feature_df=ner_df,\n    timestamp_col=\"timestamp_col\",\n    refresh_freq=\"1 minute\",\n    refresh_mode=\"INCREMENTAL\",\n    desc=\"NER and content features\",\n    online_config=OnlineConfig(enable=True, target_lag=\"30 seconds\")\n)\n\ntry:\n    ner_fv = fs.register_feature_view(\n        feature_view=ner_fv,\n        version=\"v1\",\n        overwrite=True\n    )\n    print(\"      ‚úì ner_content_features created with online serving\")\nexcept Exception as e:\n    print(f\"      ‚úó Error: {e}\")\n\nprint(\"\\n   ‚úì All feature views created WITH online config\")\n\n# ============================================================================\n# PHASE 2: Wait for Online Tables to Materialize\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 2: WAIT FOR ONLINE FEATURE TABLES TO MATERIALIZE\")\nprint(\"=\"*80)\n\nprint(\"\\nOnline feature tables need to populate from dynamic tables...\")\nprint(\"This happens automatically in the background.\")\nprint(\"Checking every 15 seconds (max 3 minutes)...\")\n\nmax_wait = 180  # 3 minutes\ncheck_interval = 15\nelapsed = 0\nall_materialized = False\n\nfeature_view_names = [\"acoustic_features\", \"emotion_sentiment_features\", \"ner_content_features\"]\n\nwhile elapsed < max_wait and not all_materialized:\n    time.sleep(check_interval)\n    elapsed += check_interval\n    \n    print(f\"\\n‚è±Ô∏è  Check at {elapsed}s:\")\n    ready_count = 0\n    \n    for fv_name in feature_view_names:\n        dt_name = f\"{fv_name.upper()}$v1\"\n        try:\n            count = session.sql(f\"\"\"\n                SELECT COUNT(*) as cnt \n                FROM BUILD25_DEV_TO_PRODUCTION.CALL_QUALITY_FS.\"{dt_name}\"\n            \"\"\").collect()[0]['CNT']\n            \n            if count > 0:\n                print(f\"   ‚úì {dt_name}: {count} rows - READY\")\n                ready_count += 1\n            else:\n                print(f\"   ‚è≥ {dt_name}: 0 rows - waiting...\")\n        except Exception as e:\n            print(f\"   ‚è≥ {dt_name}: Not materialized yet...\")\n    \n    if ready_count == len(feature_view_names):\n        all_materialized = True\n        print(\"\\n   ‚úÖ All tables have data!\")\n        break\n\nif not all_materialized:\n    print(\"\\n   ‚ö†Ô∏è  Some tables still materializing\")\n    print(\"   Online serving may still be initializing in background...\")\n\n# ============================================================================\n# PHASE 3: Test Online Retrieval\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 3: TEST ONLINE RETRIEVAL\")\nprint(\"=\"*80)\n\nprint(\"\\nWaiting 30 seconds for online tables to populate...\")\ntime.sleep(30)\n\nprint(\"\\nTesting online feature retrieval...\")\n\ntry:\n    # Get a sample call_id\n    sample_call = session.sql(\"\"\"\n        SELECT \"call_id\" \n        FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features \n        LIMIT 1\n    \"\"\").collect()[0]['call_id']\n    \n    print(f\"Testing with call_id: {sample_call}\")\n    \n    # Get feature view\n    acoustic_fv = fs.get_feature_view(\"acoustic_features\", \"v1\")\n    \n    # Try online retrieval - FIXED: Using UPPERCASE feature names that exist in acoustic_features\n    features = fs.read_feature_view(\n        feature_view=acoustic_fv,\n        version=\"v1\",\n        keys=[[sample_call]],\n        feature_names=[\"SPEAKING_RATE_WPM\", \"AVG_PITCH_HZ\", \"ENERGY_MEAN\"],\n        store_type=StoreType.ONLINE\n    )\n    \n    print(\"\\n‚úÖ SUCCESS! Online retrieval working!\")\n    print(\"\\nRetrieved features:\")\n    features.show()\n    \n    online_working = True\n    \nexcept Exception as e:\n    print(f\"\\n‚úó Online retrieval failed: {e}\")\n    print(\"\\nThis could mean:\")\n    print(\"   - Online tables still populating (wait another 1-2 minutes)\")\n    print(\"   - Online serving not available in your environment\")\n    print(\"   - Need to grant additional permissions\")\n    online_working = False\n\n# ============================================================================\n# Summary\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SETUP COMPLETE!\")\nprint(\"=\"*80)\n\nif online_working:\n    print(\"\\n‚úÖ ONLINE MODE: ENABLED AND WORKING!\")\n    print(\"\\nüìä Configuration:\")\n    print(\"   ‚Ä¢ Feature Store: CALL_QUALITY_FS\")\n    print(\"   ‚Ä¢ Feature Views: 3 (all with online serving)\")\n    print(\"   ‚Ä¢ Target Lag: 30 seconds\")\n    print(\"   ‚Ä¢ Mode: ONLINE (low-latency point lookups)\")\n    \n    print(\"\\nüéØ Next Steps:\")\n    print(\"   1. Use the ONLINE version of Streamlit dashboard\")\n    print(\"   2. Features available with <30 second latency\")\n    print(\"   3. Monitor with: fs.get_refresh_history(fv, StoreType.ONLINE)\")\n    \nelse:\n    print(\"\\n‚ö†Ô∏è  ONLINE MODE: NOT WORKING\")\n    print(\"\\nüìä Current Status:\")\n    print(\"   ‚Ä¢ Feature Store: CALL_QUALITY_FS - ‚úì\")\n    print(\"   ‚Ä¢ Feature Views: 3 (offline mode) - ‚úì\")\n    print(\"   ‚Ä¢ Dynamic Tables: Materialized - ‚úì\")\n    print(\"   ‚Ä¢ Online Serving: Failed to enable - ‚úó\")\n    \n    print(\"\\nüîÑ Options:\")\n    print(\"\\n   OPTION 1: Wait and Retry\")\n    print(\"   - Wait another 2-3 minutes\")\n    print(\"   - Run just the Phase 3 section again\")\n    print(\"   - Online tables may still be initializing\")\n    \n    print(\"\\n   OPTION 2: Use Offline Mode (RECOMMENDED)\")\n    print(\"   - Offline mode works perfectly right now\")\n    print(\"   - Query dynamic tables directly (fast)\")\n    print(\"   - Production-ready, no preview features\")\n    print(\"   - Use the OFFLINE Streamlit dashboard\")\n    \n    print(\"\\n   OPTION 3: Check Permissions\")\n    print(\"   - You may need ACCOUNTADMIN to grant:\")\n    print(\"   - CREATE ONLINE FEATURE TABLE privilege\")\n    print(\"   - Contact your Snowflake admin\")\n\nprint(\"\\n\" + \"=\"*80)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70cb311c-ec2b-412b-b51c-2463641908a9",
   "metadata": {
    "language": "python",
    "name": "STREAMLIT_DASHBOARD"
   },
   "outputs": [],
   "source": "\"\"\"\nReal-Time Agent Coaching Dashboard\nStreamlit app for live call quality monitoring and coaching\n\"\"\"\n\nimport streamlit as st\n\n# Now import everything else\nimport snowflake.snowpark as snowpark\nfrom snowflake.ml.feature_store import FeatureStore\nfrom snowflake.ml.feature_store.feature_view import StoreType\nfrom snowflake.ml.registry import Registry\nimport pandas as pd\nfrom datetime import datetime, timedelta\nimport time\n\n# Custom CSS\nst.markdown(\"\"\"\n<style>\n    .big-metric {\n        font-size: 48px;\n        font-weight: bold;\n        text-align: center;\n    }\n    .coaching-alert {\n        padding: 15px;\n        border-radius: 5px;\n        margin: 10px 0;\n        font-weight: bold;\n    }\n    .alert-high {\n        background-color: #ff4444;\n        color: white;\n    }\n    .alert-medium {\n        background-color: #ffaa00;\n        color: white;\n    }\n    .alert-good {\n        background-color: #00cc66;\n        color: white;\n    }\n</style>\n\"\"\", unsafe_allow_html=True)\n\n# Initialize session state\nif 'auto_refresh' not in st.session_state:\n    st.session_state.auto_refresh = False\n\n# ============================================================================\n# Initialize Connections\n# ============================================================================\n\n@st.cache_resource\ndef get_snowflake_connection():\n    \"\"\"Initialize Snowflake connection\"\"\"\n    try:\n        session = snowpark.Session.builder.getOrCreate()\n        return session\n    except Exception as e:\n        st.error(f\"Failed to connect to Snowflake: {e}\")\n        return None\n\n@st.cache_resource\ndef get_feature_store(_session):\n    \"\"\"Initialize Feature Store\"\"\"\n    try:\n        # Get current warehouse from session\n        current_warehouse = _session.get_current_warehouse()\n        \n        fs = FeatureStore(\n            session=_session,\n            database=\"BUILD25_DEV_TO_PRODUCTION\",\n            name=\"CALL_QUALITY_FS\",\n            default_warehouse=current_warehouse,\n            creation_mode=\"fail_if_not_exist\"\n        )\n        return fs\n    except Exception as e:\n        st.error(f\"Failed to load Feature Store: {e}\")\n        st.error(\"Make sure you've run the Feature Store setup script first!\")\n        return None\n\n# ============================================================================\n# Helper Functions\n# ============================================================================\n\ndef get_active_calls(session):\n    \"\"\"Get list of active calls\"\"\"\n    try:\n        # Get recent calls without ordering by processed_at\n        calls = session.sql(\"\"\"\n            SELECT DISTINCT \"call_id\", \"agent_id\"\n            FROM BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\n            LIMIT 20\n        \"\"\").to_pandas()\n        return calls\n    except Exception as e:\n        st.error(f\"Error loading calls: {e}\")\n        # Return empty DataFrame with correct columns\n        return pd.DataFrame(columns=['call_id', 'agent_id'])\n\ndef get_call_features(fs, call_id):\n    \"\"\"Retrieve features for a specific call from online store\"\"\"\n    try:\n        # Get feature views\n        acoustic_fv = fs.get_feature_view(\"acoustic_features\", \"v1\")\n        emotion_fv = fs.get_feature_view(\"emotion_sentiment_features\", \"v1\")\n        ner_fv = fs.get_feature_view(\"ner_content_features\", \"v1\")\n        \n        # Retrieve features - FIXED: Using UPPERCASE feature names\n        acoustic = fs.read_feature_view(\n            feature_view=acoustic_fv,\n            keys=[[call_id]],\n            feature_names=[\n                \"SPEAKING_RATE_WPM\", \"SPEECH_RATE_VARIABILITY\",\n                \"INTERRUPTION_COUNT\", \"AGENT_TALK_RATIO\",\n                \"ENERGY_MEAN\", \"AVG_PAUSE_DURATION_SEC\"\n            ],\n            store_type=StoreType.ONLINE\n        ).to_pandas()\n        \n        emotion = fs.read_feature_view(\n            feature_view=emotion_fv,\n            keys=[[call_id]],\n            feature_names=[\n                \"AVG_EMOTION_SCORE\", \"STRESS_INDICATORS\",\n                \"SENTIMENT_SCORE\", \"DOMINANT_EMOTION\"\n            ],\n            store_type=StoreType.ONLINE\n        ).to_pandas()\n        \n        ner = fs.read_feature_view(\n            feature_view=ner_fv,\n            keys=[[call_id]],\n            feature_names=[\"WORD_COUNT\", \"ENTITY_COUNT\"],\n            store_type=StoreType.ONLINE\n        ).to_pandas()\n        \n        # Combine\n        features = pd.concat([acoustic, emotion, ner], axis=1)\n        return features\n    except Exception as e:\n        st.error(f\"Error retrieving features: {e}\")\n        return None\n\ndef generate_coaching_suggestions(features):\n    \"\"\"Generate coaching suggestions based on features\"\"\"\n    suggestions = []\n    priority_scores = []\n    \n    if features is None or len(features) == 0:\n        return [], []\n    \n    row = features.iloc[0]\n    \n    # High priority alerts (RED) - FIXED: Using UPPERCASE column names\n    if row.get('STRESS_INDICATORS', 0) > 0.6:\n        suggestions.append(\"üî¥ HIGH STRESS DETECTED - Suggest calming breath or brief pause\")\n        priority_scores.append(3)\n    \n    if row.get('SENTIMENT_SCORE', 0.5) < 0.3:\n        suggestions.append(\"üî¥ VERY NEGATIVE SENTIMENT - Consider immediate escalation\")\n        priority_scores.append(3)\n    \n    # Medium priority alerts (YELLOW)\n    if row.get('SPEAKING_RATE_WPM', 150) > 180:\n        suggestions.append(\"‚ö†Ô∏è SPEAKING TOO FAST - Coach to slow down and enunciate\")\n        priority_scores.append(2)\n    \n    if row.get('INTERRUPTION_COUNT', 0) > 5:\n        suggestions.append(\"‚ö†Ô∏è EXCESSIVE INTERRUPTIONS - Practice active listening\")\n        priority_scores.append(2)\n    \n    agent_talk = row.get('AGENT_TALK_RATIO', 0.5)\n    if agent_talk > 0.7:\n        suggestions.append(\"‚ö†Ô∏è AGENT DOMINATING CONVERSATION - Ask open-ended questions\")\n        priority_scores.append(2)\n    elif agent_talk < 0.3:\n        suggestions.append(\"‚ö†Ô∏è CUSTOMER DOMINATING - Redirect conversation politely\")\n        priority_scores.append(2)\n    \n    if row.get('AVG_PAUSE_DURATION_SEC', 0) > 3:\n        suggestions.append(\"‚ö†Ô∏è LONG PAUSES - Check system response or provide updates\")\n        priority_scores.append(2)\n    \n    # Low priority (GREEN)\n    if row.get('SENTIMENT_SCORE', 0.5) > 0.7:\n        suggestions.append(\"‚úÖ POSITIVE SENTIMENT - Great job, keep it up!\")\n        priority_scores.append(1)\n    \n    if len(suggestions) == 0:\n        suggestions.append(\"‚úÖ CALL PROGRESSING WELL - No immediate action needed\")\n        priority_scores.append(1)\n    \n    return suggestions, priority_scores\n\ndef get_quality_prediction(features):\n    \"\"\"Get quality prediction (simplified for demo)\"\"\"\n    if features is None or len(features) == 0:\n        return 0, 0.5\n    \n    row = features.iloc[0]\n    \n    # Simple rule-based prediction - FIXED: Using UPPERCASE column names\n    score = 0\n    if row.get('STRESS_INDICATORS', 0) < 0.5:\n        score += 1\n    if row.get('SENTIMENT_SCORE', 0.5) > 0.5:\n        score += 1\n    if row.get('INTERRUPTION_COUNT', 0) < 3:\n        score += 1\n    if 0.4 < row.get('AGENT_TALK_RATIO', 0.5) < 0.6:\n        score += 1\n    \n    quality = 1 if score >= 3 else 0\n    confidence = score / 4\n    \n    return quality, confidence\n\n# ============================================================================\n# Main Dashboard\n# ============================================================================\n\n# Header\nst.title(\"üéØ Real-Time Agent Coaching Dashboard\")\nst.markdown(\"Live call quality monitoring and instant coaching suggestions\")\n\n# Sidebar\nwith st.sidebar:\n    st.header(\"‚öôÔ∏è Controls\")\n    \n    # Auto-refresh toggle\n    auto_refresh = st.checkbox(\"Auto-refresh (5s)\", value=st.session_state.auto_refresh)\n    st.session_state.auto_refresh = auto_refresh\n    \n    if st.button(\"üîÑ Refresh Now\"):\n        st.rerun()\n    \n    st.markdown(\"---\")\n    st.header(\"üìä Filters\")\n    show_all_calls = st.checkbox(\"Show all calls\", value=True)\n    \n    st.markdown(\"---\")\n    st.info(\"üí° **Tip:** Select a call to see detailed coaching suggestions\")\n\n# Initialize connections\nsession = get_snowflake_connection()\nif session is None:\n    st.error(\"Cannot connect to Snowflake\")\n    st.stop()\n\nfs = get_feature_store(session)\nif fs is None:\n    st.error(\"Cannot load Feature Store\")\n    st.stop()\n\n# Get active calls\ncalls_df = get_active_calls(session)\n\nif calls_df.empty:\n    st.warning(\"No active calls found. Please check if data exists in BUILD25_DEV_TO_PRODUCTION.DATA.call_acoustic_features\")\n    st.stop()\n\n# Verify columns exist\nif 'call_id' not in calls_df.columns or 'agent_id' not in calls_df.columns:\n    st.error(f\"Expected columns not found. Available columns: {calls_df.columns.tolist()}\")\n    st.stop()\n\n# ============================================================================\n# Call Selection\n# ============================================================================\n\nst.header(\"üìû Active Calls\")\n\n# Create columns for call selection\ncol1, col2 = st.columns([3, 1])\n\nwith col1:\n    selected_call = st.selectbox(\n        \"Select a call to monitor:\",\n        options=calls_df['call_id'].tolist(),\n        format_func=lambda x: f\"Call: {x} | Agent: {calls_df[calls_df['call_id']==x]['agent_id'].values[0]}\"\n    )\n\nwith col2:\n    st.metric(\"Total Active\", len(calls_df))\n\n# ============================================================================\n# Real-Time Monitoring\n# ============================================================================\n\nif selected_call:\n    st.markdown(\"---\")\n    st.header(f\"üé§ Monitoring Call: {selected_call}\")\n    \n    # Get features\n    with st.spinner(\"Loading call data...\"):\n        features = get_call_features(fs, selected_call)\n    \n    if features is not None and len(features) > 0:\n        # Get prediction\n        quality, confidence = get_quality_prediction(features)\n        \n        # Top metrics row\n        col1, col2, col3, col4 = st.columns(4)\n        \n        with col1:\n            quality_color = \"üü¢\" if quality == 1 else \"üî¥\"\n            st.markdown(f\"### {quality_color} Call Quality\")\n            st.markdown(f\"<div class='big-metric'>{'HIGH' if quality == 1 else 'LOW'}</div>\", \n                       unsafe_allow_html=True)\n            st.progress(confidence)\n        \n        with col2:\n            stress = features.iloc[0].get('STRESS_INDICATORS', 0)\n            stress_color = \"üî¥\" if stress > 0.6 else \"üü°\" if stress > 0.4 else \"üü¢\"\n            st.markdown(f\"### {stress_color} Stress Level\")\n            st.markdown(f\"<div class='big-metric'>{stress:.1%}</div>\", unsafe_allow_html=True)\n            st.progress(stress)\n        \n        with col3:\n            sentiment = features.iloc[0].get('SENTIMENT_SCORE', 0.5)\n            sent_color = \"üü¢\" if sentiment > 0.6 else \"üü°\" if sentiment > 0.4 else \"üî¥\"\n            st.markdown(f\"### {sent_color} Sentiment\")\n            st.markdown(f\"<div class='big-metric'>{sentiment:.1%}</div>\", unsafe_allow_html=True)\n            st.progress(sentiment)\n        \n        with col4:\n            interruptions = int(features.iloc[0].get('INTERRUPTION_COUNT', 0))\n            int_color = \"üî¥\" if interruptions > 5 else \"üü°\" if interruptions > 3 else \"üü¢\"\n            st.markdown(f\"### {int_color} Interruptions\")\n            st.markdown(f\"<div class='big-metric'>{interruptions}</div>\", unsafe_allow_html=True)\n        \n        st.markdown(\"---\")\n        \n        # Coaching Suggestions\n        col1, col2 = st.columns([2, 1])\n        \n        with col1:\n            st.header(\"üí° Real-Time Coaching Suggestions\")\n            suggestions, priorities = generate_coaching_suggestions(features)\n            \n            for suggestion, priority in zip(suggestions, priorities):\n                if priority == 3:\n                    st.markdown(f\"<div class='coaching-alert alert-high'>{suggestion}</div>\", \n                               unsafe_allow_html=True)\n                elif priority == 2:\n                    st.markdown(f\"<div class='coaching-alert alert-medium'>{suggestion}</div>\", \n                               unsafe_allow_html=True)\n                else:\n                    st.markdown(f\"<div class='coaching-alert alert-good'>{suggestion}</div>\", \n                               unsafe_allow_html=True)\n        \n        with col2:\n            st.header(\"üìä Call Metrics\")\n            \n            row = features.iloc[0]\n            \n            st.metric(\"Speaking Rate\", f\"{row.get('SPEAKING_RATE_WPM', 0):.0f} WPM\")\n            st.metric(\"Agent Talk Ratio\", f\"{row.get('AGENT_TALK_RATIO', 0):.1%}\")\n            st.metric(\"Pause Duration\", f\"{row.get('AVG_PAUSE_DURATION_SEC', 0):.1f}s\")\n            st.metric(\"Word Count\", f\"{int(row.get('WORD_COUNT', 0))}\")\n            st.metric(\"Entities\", f\"{int(row.get('ENTITY_COUNT', 0))}\")\n        \n        # Detailed Features (Expandable)\n        with st.expander(\"üîç View All Features\"):\n            st.dataframe(features.T, use_container_width=True)\n    \n    else:\n        st.error(\"Could not load features for this call\")\n\n# Auto-refresh logic\nif st.session_state.auto_refresh:\n    time.sleep(5)\n    st.rerun()\n\n# Footer\nst.markdown(\"---\")\nst.caption(\"üéØ Real-Time Agent Coaching Dashboard | Powered by Snowflake ML & Feature Store\")",
   "execution_count": null
  }
 ]
}